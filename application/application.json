[{"id":"android.mdx","slug":"android","body":"\nimport N from \"@n/N.astro\";\n\n## Information\n\nJoin the global Android community of millions of users and developers who collaborate to improve the open-source mobile operating system, giving you endless possibilities to customize your device.\nUnleash your creativity and make your smartphone, tablet, or smartwatch truly your own with the endless array of apps and features available on Android, tailored to fit your unique needs and preferences.\nOur job at KBVE will be to provide you with everything you need to deploy your own Android application on almost any device!\n\n## Introduction\n\nEverything you need to get started with Android!\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n## Cheatsheet\n\nThe ADB cheatsheet provides a general list of basic commands for Android operating system and applications.\nPlease note that certain commands require the device to be rooted, furthermore certain Android versions may require a tweak to the commands.\n\n### Device Commands\n\nAndroid ADB Device commands are commands that you can use to control the Android device over USB from a computer.\nYou can use them to list all devices, restart server and reboot!\n\n- `adb devices` - List all connected devices.\n\n  - `adb devices -l` - Query additional information from devices.\n  - `adb get-state` - Information on the device state.\n  - `adb get-serialno` - Query the device serial number.\n\n- `adb root` - Launch module adbd with root permission.\n  - Error 1: `adbd cannot run as root in production builds`\n    - Resolution:\n- `adb start-server` - Start the adb server.\n- `adb kill-server` - Terminate the adb server.\n- `adb reboot` - Restart the current device.\n- `adb help` - Display additional information.\n\n### Shell\n\n> Warning: Shell commands can brick your operating system, so make sure to double check them before running.\n\nADB shell is a command-line interface that you can use to access the shell and run various commands on your Android device.\nYou can use ADB shell commands to perform actions such as changing the resolution of your device display, uninstalling bloatware or system apps, enabling and disabling features, modifying the system files, ect..\n\n> Remember to keep a backup of the commands that you run via shell, I recommend creating a `log.txt` file and output all the commands to that file.\n\n- `adb shell` - Launch the shell terminal for the device.\n- `adb -s $deviceString $deviceCommand` - Send the $deviceCommand to a specific device named $deviceString\n- `adb shell pwd` - Command to list current directory.\n- `adb shell ls` - Command to list all the directory contents of the device.\n  - `adb shell ls -s` - Additional size information.\n  - `adb shell ls -R` - Recursion of the folders.\n- `adb shell netstat` - Query the TCP information\n- `adb shell dumpsys` - An android tool that dumps information related to system services.\n  - `adb shell dumpsys iphonesybinfo` - Query the IMEI information.\n  - `adb shell dumpsys battery` - Query battery information.\n    - `adb shell dumpsys battery set level $v` - Device battery level from 0 to 100.\n    - `adb shell dumpsys battery reset` - Reset the device battery.\n  - `adb shell dumpsys activity $package` - Query activity of package.\n- `adb shell pm list features` - Query device features.\n- `adb shell service list` - Query device services.\n- `adb shell wm` - ◈Null\n  - `adb shell wm size` - Current device screen resolution.\n    - `adb shell wm size $WxH` - Change device screen resolution.\n    - `adb shell wm size reset` - Reset device screen resolution.\n  - `adb shell wm density` - ◈Null\n    - `adb shell wm density reset` - Reset device density.\n- `adb shell ps` - Query process status on the device.\n- `exit` - To exit ADB.\n\n---\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n---\n\n### Key Events\n\nAndroid Key Events - A quick breakdown for each event and how the operating system handles them.\n\nGeneric Android Keyevents:\n\n- `adb shell input keyevent`\n\n  - `adb shell input keyevent 0` - Keycode 0\n  - `adb shell input keyevent 1` - Soft Left\n  - `adb shell input keyevent 2` - Soft Right\n  - `adb shell input keyevent 3` - Home Button Event.\n  - `adb shell input keyevent 4` - Back Button Event.\n  - `adb shell input keyevent 5` - Call Event.\n  - `adb shell input keyevent 6` - End Call / Hangup Event.\n  - Events 7 to 18 are generic cell phone events.\n    - `adb shell input keyevent 7` - Keycode 0\n    - `adb shell input keyevent 8` - Keycode 1 aka Number 1\n    - `adb shell input keyevent 9` - Keycode 2 aka Number 2\n    - `adb shell input keyevent 10` - Keycode 3 aka Number 3\n    - `adb shell input keyevent 11` - Keycode 4 aka Number 4\n    - `adb shell input keyevent 12` - Keycode 5 aka Number 5\n    - `adb shell input keyevent 13` - Keycode 6 aka Number 6\n    - `adb shell input keyevent 14` - Keycode 7 aka Number 7\n    - `adb shell input keyevent 15` - Keycode 8 aka Number 8\n    - `adb shell input keyevent 16` - Keycode 9 aka Number 9\n    - `adb shell input keyevent 17` - STAR Key\n    - `adb shell input keyevent 18` - Pound Key\n\n- Koltin: `open class KeyEvent: InputEvent, Parcelable`\n\n- Java: `pulibc class KeyEvent extends InputEvent implements Parcelable`\n\n## System Information\n\n## Errors\n\n## Videos\n\n<N ns=\"c\" template=\"yt\" data=\"https://www.youtube.com/watch?v=fis26HvvDII\" />\n\n---\n\n<N ns=\"c\" template=\"yt\" data=\"https://www.youtube.com/watch?v=aS__9RbCyHg\" />\n\n---\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n---\n\n## Notes\n\nNotes for Android MDX.\n\n### Log\n\n- [ ] Need more information and data for the Android MDX.\n- [ ] Add Namespace into the Android MDx.\n\n#### Journal\n\n##### 2023-04-15\n\nTesting the tabs for Android MDX\n","collection":"application","data":{"title":"Android","description":"Android is an open source operating system based off of Linux that runs within the ARM architecture; the primary use-case is within the mobile/tablet eco-system but it has been expanding into server, desktop and embedables.","tags":["technology","android","debug","mobile"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1607252650355-f7fd0460ccdb?fit=crop&w=1400&h=700&q=75"}},{"id":"ansible.mdx","slug":"ansible","body":"\nimport N from \"@n/N.astro\";\n\n\n## Information\n\n> Automation software that enables `IaC` - also known as, infrastructure as code, thus allowing user to provision, configure, deploy and secure a whole array of software, applications and machines.\n\nWith Ansible, you can automate complex IT tasks with minimal effort and maximum efficiency.\nAnsible lets you manage systems, deploy applications, and coordinate workflows with simple and powerful modules.\nAnsible is a versatile and secure automation tool that harnesses the power of open source, Python, and SSH to connect and automate your devices.\nThe software / application works by connecting to your devices by sending out tiny programs called modules that perform your tasks with precision and speed.\nAnsible can help you automate provisioning, configuration management, application deployment, and many other manual IT processes\n\n### Metaphor for Ansible\n\nThink of it like:\n\n- Ansible is like a remote control that lets you manage your devices with the push of a button.\n- Ansible is like a chef that prepares a delicious meal using different ingredients and recipes.\n- Ansible is like a conductor that orchestrates a symphony of servers and applications.\n\n\n### Ansible described for a 5yr old!\n\nAnsible is a tool that helps people do things with computers.\nSometimes people have many computers and they want to do the same thing on all of them.\nFor example, they might want to make them play a game, or show a picture, or talk to each other.\nDoing the same thing on many computers can be hard and boring.\nAnsible makes it easy and fun and has a list of things that people want to do with computers.\nIt can read the list and do the things one by one and then also check if the things are done correctly.\nAnsible can talk to different kinds of computers and tell them what to do.\nThink of Ansible like a friend that helps people with computers.\n\n\n---\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n---\n\n## Install\n\nTo install Ansible, you need two machines: a control node and a managed node.\nThe control node is where you run Ansible commands and playbooks, and the managed node is where Ansible performs the tasks.\nThe control node can be any UNIX-like machine with Python 3.9 or newer installed, while the managed node can be any device that supports Python 2.7 or newer and SSH or PowerShell remoting.\n\nDepending on your operating system, you can install Ansible from different sources.\nFor example, on Ubuntu, you can use the apt package manager to install Ansible from the official repositories.\nOn Windows, you can use Windows Subsystem for Linux (WSL) to install Ansible from PyPI using pip / pip3.\nYou can also install Ansible from source code if you want to use the latest development version.\n\nAfter installing Ansible, you need to configure it by setting up the inventory file that lists the managed nodes and their connection details.\nYou can also customize and fine-tune other settings in the `ansible.cfg` file or by using environment variables or command-line options.\nTo confirm that Ansible is installed and configured correctly, you can run the ansible command with the ping module to test the connectivity and responsiveness of your managed nodes.\n\n### Need extra installation help?\n\n[Ask our support team?](https://kbve.com/support/) or visit our [Discord](https://kbve.com/discord/)\n\nIf you need help with [Python, read our docs](https://kbve.com/application/python/)\n\n\n---\n\n## Playbook\n\nAn Ansible playbook is your automation blueprint written in YAML/JSON.\nIt tells Ansible what to do, where to do it, and how to do it.\nWith a playbook, you can transform your IT tasks into simple and repeatable steps that run on any number of hosts.\nWhether you need to install software, configure settings, run commands, or anything else, an Ansible playbook will make it happen in a snap.\n\n### Playbook Examples\n\nLet me dazzle you with an example of a playbook that I borrowed from the Ansible documentation.\n\n```yaml\n---\n- name: Update web servers\n  hosts: webservers\n  remote_user: root\n  tasks:\n    - name: Ensure apache is at the latest version\n      ansible.builtin.yum:\n        name: httpd\n        state: latest\n    - name: Write the apache config file\n      ansible.builtin.template:\n        src: /srv/httpd.j2\n        dest: /etc/httpd.conf\n\n- name: Update db servers\n  hosts: databases\n  remote_user: root\n  tasks:\n    - name: Ensure postgresql is at the latest version\n      ansible.builtin.yum:\n        name: postgresql\n        state: latest\n    - name: Ensure that postgresql is started\n      ansible.builtin.service:\n        name: postgresql\n        state: started\n```\n\nThis playbook has two plays.\nThe first one updates the web servers by installing the latest version of apache and writing a config file.\nThe second one updates the database servers by installing the latest version of postgresql and starting the service.\nEach play has a name, a list of hosts to target, a remote user to execute the tasks, and a list of tasks to perform.\nEach task has a name and a module to call with some parameters.\n\n#### Minecraft Server Update Playbook\n\n```yaml\n- name: Update Minecraft server\n  hosts: minecraft\n  vars:\n    minecraft_version: latest\n    minecraft_url: https://s3.amazonaws.com/Minecraft.Download/versions\n    minecraft_home: /srv/minecraft\n  tasks:\n    - name: Get latest Minecraft version\n      uri:\n        url: \"{{ minecraft_url }}/latest.json\"\n        return_content: yes\n      register: latest_version\n      when: minecraft_version == \"latest\"\n\n    - name: Set Minecraft version\n      set_fact:\n        minecraft_version: \"{{ latest_version.json.id }}\"\n      when: minecraft_version == \"latest\"\n\n    - name: Check if Minecraft server jar exists\n      stat:\n        path: \"{{ minecraft_home }}/minecraft_server.{{ minecraft_version }}.jar\"\n      register: jar_file\n\n    - name: Download Minecraft server jar\n      get_url:\n        url: \"{{ minecraft_url }}/{{ minecraft_version }}/minecraft_server.{{ minecraft_version }}.jar\"\n        dest: \"{{ minecraft_home }}\"\n      when: not jar_file.stat.exists\n\n    - name: Restart Minecraft service\n      systemd:\n        name: minecraft\n        state: restarted\n      when: not jar_file.stat.exists\n```\n\nThis playbook is composed of four parts:\n\n- The name of the playbook, which is `Update Minecraft server`.\n- The hosts that the playbook will run on, which are the ones in the `minecraft` group in the inventory file.\n- The variables that the playbook will use, such as `minecraft_version`, `minecraft_url`, and `minecraft_home`.\n- The tasks that the playbook will execute, such as getting the latest Minecraft version, downloading the server jar file, and restarting the Minecraft service.\n\nEach task has a name, a module to use, and some parameters for the module.\nSome tasks also have a condition (`when`) that determines when they will run.\nFor example, the task `Download Minecraft server jar` will only run if the jar file does not exist in the `minecraft_home` directory.\nThe playbook uses the `register` keyword to store the output of some tasks in variables, such as `latest_version` and `jar_file`.\nThese variables can be used in later tasks or conditions and this playbook could be expanded to include file checks with hashing.\n\n---\n\n## Modules\n\n> tldr; Ansible has a large collection of modules that can be used for various tasks and purposes.\n\n---\n\n### Cloud Modules\n\nCloud modules can be used to interact with different cloud providers, such as AWS, Azure, Google Cloud, etc.\n\nThe cloud modules within Ansible are a set of modules that can be used to interact with different cloud providers and services.\nThey allow you to provision, configure and manage cloud resources, such as virtual machines, networks, storage, databases, etc.\n\n#### AWS Modules\n\nThese modules can be used to work with Amazon Web Services (AWS), such as EC2, S3, CloudFormation, etc.\nFor example, you can use the `ec2_instance` module to create and manage EC2 instances on AWS.\n\n#### Azure Modules\n\nWith these modules, you have full control over your Microsoft Azure resources, whether they are VMs, Storage, Network or anything else.\nFor example, you can use the `azure_rm_virtualmachine` module to create and manage Azure virtual machines.\n\n#### GCP Modules\n\nYou can work with any Google Cloud Platform service with these modules, such as Compute Engine, Storage, Network and more.\nThe `gcp_compute_instance` module is an example of how you can achieve your goals with GCP servers using Ansible.\n\n> [Official Documentation on GCP Compute Instance module](https://docs.ansible.com/ansible/latest/collections/google/cloud/gcp_compute_instance_module.html)\n\n##### Create GCP Instance\n\nCreating a compute instance with a specific name, zone, machine type, image and network:\n\n```yaml\n- name: create gcp instance\n  google.cloud.gcp_compute_instance:\n    name: test_object\n    zone: us-central1-a\n    machine_type: n1-standard-1\n    disks:\n      - auto_delete: true\n        boot: true\n        source: \"{{ disk }}\"\n    network_interfaces:\n      - network: \"{{ network }}\"\n        access_configs:\n          - name: External NAT\n            nat_ip: \"{{ address }}\"\n            type: ONE_TO_ONE_NAT\n    state: present\n```\n\nThis example creates a compute instance with a specific name, zone, machine type, image and network.\nIt uses the `state: present` parameter to indicate that the instance should exist.\nIt also specifies the `disks` and `network_interfaces` parameters to configure the disk and network settings of the instance.\nThe `disk` and `network` variables are assumed to be defined elsewhere in the playbook or inventory.\n\n##### Delete GCP Instance\n\nDeleting a compute instance with a specific name and zone:\n\n```yaml\n- name: dlete gcp instance\n  google.cloud.gcp_compute_instance:\n    name: test_object\n    zone: us-central1-a\n    state: absent\n```\n\nFor this task, it deletes a compute instance with a specific `name` and `zone`.\nIt uses the `state: absent` parameter to indicate that the instance should not exist.\nIt does not need to specify any other parameters, as the `name` and `zone` are enough to identify the instance to delete.\n\n##### Update GCP Instance\n\nUpdating a compute instance with a new machine type and labels\n\n```yaml\n- name: update gcp instance\n  google.cloud.gcp_compute_instance:\n    name: test_object\n    zone: us-central1-a\n    machine_type: n1-standard-2\n    labels:\n      env: prod\n      webserver: nginx\n    state: present\n```\n\nThe update example performs the task of updating a compute instance with a new machine type and labels.\nIt uses the `state: present` parameter to indicate that the instance should exist.\nIt also specifies the `machine_type` and `labels` parameters to change the machine type and labels of the instance.\nThe machine type determines the CPU and memory resources of the instance, and the labels are key-value pairs that can be used to organize and filter instances.\nAny other parameters that are not specified will remain unchanged.\n\n---\n\n#### OpenStack Modules\n\nOpenStack modules can be used to work with OpenStack, an open source cloud platform that provides infrastructure as a service (IaaS).\nThe `os_server` module is an example of how you can have full control over your OpenStack servers.\n\n---\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n---\n\n### Network Modules\n\nYou can configure and manage any network device with these modules, such as routers, switches, firewalls and beyond.\n\n### System Modules\n\nWith these modules, you have full control over your system resources, whether they are users, groups, files, directories, services, packages or anything else.\n\n### Database Modules\n\nEmploying these modules, you have full control over your database servers and objects, from MySQL and PostgreSQL to MongoDB and more.\n\n### Windows Modules\n\nWindows modules can be used to manage Windows systems and applications, such as Active Directory, IIS, PowerShell, etc.\nFor example, you can use the `win_service` module to manage Windows services.\n\n---\n\n## AWX\n\n> tldr; AWX is a web-base RESTFul API and task engine that operates on top of Ansible, thus enabling you to automate certain aspects of the IT/DevOps.\n\nAWX is an open source project that gives you a sleek and modern web-based user interface, a powerful and flexible REST API, and a robust and scalable task engine to work with Ansible.\nIt is the upstream project of Red Hat Ansible Automation Platform, which is a premium solution that offers additional features and support for enterprise customers.\nWith AWX, you can easily manage your Ansible playbooks, inventories, credentials, and vaults in a collaborative and secure way among your team members.\nMoreover, AWX empowers you to plan and run your Ansible playbooks on your managed nodes with speed, efficiency and dependability; you can set up custom schedules, workflows, notifications, and callbacks to automate your Ansible operations and monitor their outcomes.\nIn conclusion, AWX gives you full control and visibility over your Ansible playbooks and their execution.\n\n### AWX Repo\n\n> The official [Repository](https://github.com/ansible/awx) for AWX - Ansible.\n\nThe AWX repository is a GitHub repository that contains a treasure trove of source code and other resources.\n\n---\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n---\n\n### AWX Terraform\n\n> More information on [Terraform](https://kbve.com/application/terraform)\n\nTerraform AWX Provider from Denouche.\n\nBy using AWX and Terraform together, you can leverage the power and flexibility of Ansible to manage your AWS resources with ease and efficiency.\nThe Two tools that can be used together to automate IT infrastructure.\n\n- Official [Registry](https://registry.terraform.io/providers/denouche/awx/latest/docs) Link:\n\nExample Usage - With Username/Password:\n\n```ini\nprovider \"awx\" {\n    hostname = \"http://localhost:8078\"\n    username = \"kbvetest\"\n    password = \"changemepassword\"\n}\n```\n\nExample Usage - With Token:\n\n```ini\nprovider \"awx\" {\n  hostname = \"http://localhost:8078\"\n  token    = \"awxtoken\"\n}\n```\n\n> Remember that if you set both (username/password) and (token), then the (token) will have precedence.\n\n\n---\n\n## Cheatsheet\n\n> tldr; Commands that will make it easier operate ansible scripts / playbooks. This cheatsheet is still a work-in-progress.\n\nAn Ansible cheatsheet is a quick and handy reference guide that provides examples and tips on how to use Ansible command line tools and playbooks, thus enabling you to unleash the power of Ansible!\nWith an Ansible cheatsheet at your fingertips, you can breeze through a variety of tasks that would otherwise be tedious and time-consuming.\nWhether you need to test the connectivity to your nodes, switch to a different user, use a custom SSH key, use password-based authentication, run ad-hoc commands, create and run playbooks, use modules and roles, or anything else, an Ansible cheatsheet will make your life easier and more fun.\n\n## Videos\n\nWe will be adding more videos.\n\n<N ns=\"c\" template=\"yt\" data=\"https://www.youtube.com/watch?v=EcnqJbxBcM0\" />\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n## Notes\n\nWe should start to include all the playbooks that we have written! \n\n### Log\n\n- [ ] Add some videos for Ansible.\n- [ ] Include Ansible + n8n integration content.\n\n#### Journal\n\n##### 2023-04-16\nAdded tabs to the Ansible MDX.\n\n###### 2023-04-10\nGoing to update the basics of the documentation. I will go back and add moreinformation next week.\n\n### License\n","collection":"application","data":{"title":"Ansible","description":"DevOps software that handles the infrastructure of the backend through automation. Ansible's main function(s) operate through a \"playbook\" system that exectues a collection of commands for the system admin, which becomes a pillar within the IaaC environment.","tags":["technology","automation","host"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1549605659-32d82da3a059?fit=crop&w=1400&h=700&q=75"}},{"id":"appwrite.mdx","slug":"appwrite","body":"\nimport N from \"@n/N.astro\";\n\n## Information\n\nAppwrite is a cutting-edge backend server that streamlines the development of modern apps. \nWith its powerful APIs, intuitive tools, and sleek management console UI, Appwrite empowers developers to build their apps with speed and security. \nSay goodbye to the headaches of common, complex, and repetitive tasks - Appwrite has got you covered. \nGet ready to revolutionize your app development process with Appwrite!\n\n---\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n---\n\n## Install\n\n## Cheatsheet\n\n\n## System\n\n\n## Guides\n\nTODO\n\n## Videos\n\n---\n\n## Notes\n\nThese will be all the notes for AppWrite, as we migrate over to it.\n\n### Log\n\n- [ ] Add Guides for AppWrite\n- [ ] Add Videos for AppWrite\n\n#### Journal\n\n##### 2023-04-14\nAdded email configuration to the appwrite server variables.\n\n##### 2023-04-12\nStarting the mdx sheet for AppWrite. I will try to include all the reference material here.\n\n### License\n\n#### Appwrite License\n\nAppwrite / appwrite is licensed under the BSD 3-Clause \"New\" or \"Revised\" License located here [license.md](https://github.com/appwrite/appwrite/blob/master/LICENSE)\n","collection":"application","data":{"title":"AppWrite","description":"Appwrite is an open-source backend server that provides developers with core APIs to build applications. It is self-hosted and can run on any operating system. Appwrite aims to simplify backend development for developers.","tags":["auth","api","backend"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1581291518857-4e27b48ff24e?fit=crop&w=1400&h=700&q=75"}},{"id":"authelia.mdx","slug":"authelia","body":"\nimport GitHub from \"@w/Github.astro\";\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport YT from \"@w/YT.astro\";\nimport N from \"@n/N.astro\";\n\n<TabMenu first=\"general\" data={[\"cheatsheet\", \"system\", \"errors\", \"media\", \"notes\"]}>\n  <TabData tail=\"block\" data=\"general\">\n\n## Information\n\n> Tldr; Authelia is an authentication and authorization application that provides a backend server and frontend portal through various core features and plugins.\n\nHave you ever wondered how to secure your web applications with a simple, secure and elegant solution?\nDo you want to offer your users a seamless and convenient login experience across multiple domains and services?\nIf so, you might be interested in Autheila, an open-source authentication and authorization server that provides two-factor authentication and single sign-on (SSO) for your applications via a web portal.\nIn this document, KBVE will introduce you and your dev team to the features and benefits of Autheila, and show you how to set it up with some common reverse proxies like [Nginx](https://kbve.com/application/nginx), [Traefik](https://kbve.com/application/traefik), or HAProxy.\nBy the end of this reference document, you will be able to protect your web applications with Autheila and enjoy a secure and hassle-free authentication process.\n\n<Details data=\"Metaphor for Autheila\">\n\n### Metaphor\n\nAutheila is a gatekeeper!\nAutheila acts as a gatekeeper for your web applications, allowing or denying access based on your authentication and authorization policies.\nIt also provides a single key for your users to unlock multiple gates, saving them time and hassle.\nAutheila is like a smart and reliable gatekeeper that keeps your web applications safe and user-friendly.\n\n</Details>\n\n<Details data=\"Autheila for a 5yr old!\">\n### 5\n\nImagine you have a lot of toys that you like to play with on different websites.\nSome of them are your own toys, and some of them are shared with your friends.\nYou do not want anyone else to take or break your toys, so you need a way to keep them safe.\nAutheila is like a special friend who helps you do that.\nAutheila asks you for your name and a secret code every time you want to play with your toys.\nSometimes, Autheila also asks you for another secret code that only you know or have.\nThis way, Autheila makes sure that it is really you and not someone else who wants to play with your toys.\nAutheila also remembers your name and secret codes for all the websites, so you don’t have to type them again and again.\nYou just have to tell Autheila once, and then you can play with any toy you want.\nAutheila is like a smart and helpful friend who protects your toys and makes it easy for you to play with them.\n\n</Details>\n\n## Install\n\nThere are different methods to install Authelia, depending on your preferences and environment.\n\n</TabData>\n\n<TabData data=\"cheatsheet\">\n\n## Cheatsheet\n\nAutheila\n\n</TabData>\n\n<TabData data=\"system\">\n\n## System\n\nSystem resources, information and general help.\n\n\n</TabData>\n\n<TabData data=\"errors\">\n\n## Errors\n\nCommon errors within Authelia that our team has ran across.\n\n</TabData>\n\n<TabData data=\"media\">\n\n## Videos\n\nAuthelia videos that will help you with installing, updating and other things.\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Notes\n\nNotes on Authelia\n\n### Log\n\n#### Journal\n\n<Details data=\"2023-04-15\">Added a test case for the tab system. Looking to see if there might be any other issues when building out the system.</Details>\n<Details data=\"2023-04-11\">Added a quick details component to make the page a bit less clustered</Details>\n<Details data=\"2023-04-10\">General Authelia information and concepts.</Details>\n\n### License\n\n- Authelia is an open source application.\n- Authelia operates under the Apache 2.0 license.\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n</TabData>\n</TabMenu>\n","collection":"application","data":{"title":"Authelia","description":"Open-source auth software as a middleware. Authelia handles the authentication and authorization of the user/entity, allowing to secure access outside the scope of the application and provides a unique firewall-like access terminal.","tags":["security","host","firewall"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1509822929063-6b6cfc9b42f2?fit=crop&w=1400&h=700&q=75"}},{"id":"cubejs.mdx","slug":"cubejs","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n<TabMenu first=\"general\" data={[\"guides\", \"media\", \"notes\"]}>\n<TabData tail=\"block\" data=\"general\">\n\n## Information\n\nIf you are looking for a powerful and flexible framework to build amazing data applications, you should check out CubeJS. \nCubeJS is an open source project that lets you connect to any SQL-based data source, define your data models in a simple and consistent way, and expose them to your applications via blazing-fast APIs.\nWhether you want to create an internal dashboard for your business insights, or a customer-facing analytics feature for your product, CubeJS has you covered.\nCubeJS supports REST, SQL, and GraphQL APIs, so you can choose the best option for your needs.\nCubeJS also integrates seamlessly with popular data visualization tools, such as D3.js, Google Charts, Highcharts, and more. \nThis documentation will have plenty of tutorials, examples, and demos that will help you get started and inspired.\n\n### Metaphor\n\nCubeJS is like a Swiss Army knife for data applications.\nIt has multiple tools and features to help you access, organize, and deliver data from any source.\nYou can use it for different purposes and scenarios, depending on your needs and preferences.\nCubeJS is versatile, reliable, and easy to use.\n\n### 5\n\n> Explaining CubeJS application to a 5 year old\n\nYou know how you have different books and magazines that you like to read?\nSometimes you want to read one book, and sometimes you want to read another.\nIn some cases you want to read with your family, and sometimes you want to read by yourself. \nPerhaps you want to read in your bed, and sometimes you want to read on the couch.\nCubeJS is something that helps you read your books and magazines in different ways.\nIt lets you choose which book or magazine you want to read, and where you want to read it.\nIt also lets you share your books and magazines with your friends, so they can read them too.\nCubeJS makes reading your books and magazines more fun and easy.\n\n* * *\n\n## Install\n\nThere are several ways to install CubeJS, including using it as a SaaS via CubeJS Cloud.\nWe will go over a couple ways in this reference document.\n\n### Docker\n\nThere are a couple ways that we can deploy CubeJS via Docker, including dev mode and swarm.\n\n\nThese following commands will run CubeJS in a docker container and expose it on port 4000 / 3000. \nFurthermore, it will also mount the current directory as a volume for CubeJS configuration and schema files.\n\n```shell\ndocker run -d -p 3000:3000 -p 4000:4000 \\\n  -e CUBEJS_DB_HOST=postgres://hostname \\\n  -e CUBEJS_DB_NAME=<DB_NAME> \\\n  -e CUBEJS_DB_USER=<USER> \\\n  -e CUBEJS_DB_PASS=<PASS> \\\n  -e CUBEJS_DB_TYPE=<DB_TYPE> \\\n  -e CUBEJS_API_SECRET=<API_SECRET> \\\n  -v $(pwd):/cube/conf \\\n  cubejs/cube:latest\n```\n\nTo enable dev mode, pass along the environmental variable `-e CUBEJS_DEV_MODE=true \\` inside of the command.\n\nFor the Docker Swarm, we recommend that you deploy a CubeJS Docker Compose via Portainer or your swarm platform of choice.\n\n### NodeJS\n\n> Reference to additional [NodeJS docs](https://kbve.com/application/javascript/#nodejs)\n\nFor installing via NodeJS, we recommend you install cubejs-cli using npm or yarn, which are tools that help you manage JavaScript packages. You can run this command in your terminal:\n\n- NPM\n```shell\nnpm install -g cubejs-cli\n```\n\n- YARN\n```shell\nyarn add cubejs-cli\n```\n\nAfter the installation, we recommend that you launch a test case.\n\nCreate a new CubeJS project using cubejs create command.\nYou need to specify the name of your project and the type of your data source. \nFor example, if you want to use Postgres, which is a database system, you can run this command:\n\n```shell\ncubejs create dashboard-backend -d postgres\n```\n\nThis will create a new folder with your project files and install the necessary dependencies. \nYou can then start your CubeJS server by running this command inside your project folder:\n\n- NPM\n```shell\nnpm run dev\n```\n\n- YARN\n```shell\nyarn dev\n```\n\nThis will start your CubeJS test case server on `http://localhost:4000`. \nYou can then open this URL in your browser and follow the instructions to connect to your data source and start building your data model and queries.\n\n* * *\n\n## Update\n\nTo upgrade CubeJS, you need to update the version of the CubeJS package that you are using.\nThere are different ways to do that, depending on how you installed CubeJS.\n\n### Update Docker\n\nIf you are using Docker, you can upgrade CubeJS by pulling the latest image from the Docker Hub. \nYou can run this command in your terminal:\n```shell\ndocker pull cubejs/cube:latest\n```\n\n### Update NodeJS\n\nIf you are using Node.js, you can upgrade CubeJS by updating the version of the `@cubejs-backend/server` or `@cubejs-backend/server-core` package in your `package.json` file. \nYou can also use npm or yarn to update the package. For example, you can run this command in your terminal:\n\n- NPM\n```shell\nnpm update @cubejs-backend/server\n```\n\n- YARN\n```shell\nyarn upgrade @cubejs-backend/server\n```\n\n***\n\n</TabData>\n<TabData data=\"guides\">\n\n## Guides\n\nCubeJS Guides\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Notes\n\n</TabData>\n</TabMenu>","collection":"application","data":{"title":"CubeJS","description":"CubeJS is a headless business intelligence application for various forms of data, including SQL, Mongo and Snowflake. CubeJS can be extended to external data warehouses, such as, Google BigQuery, Amazon Athena and Presto.","tags":["technology","data","sql","cloud"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1635492491273-455af7728453?fit=crop&w=1400&h=700&q=75"}},{"id":"docker.mdx","slug":"docker","body":"\nimport N from \"@n/N.astro\";\n\n## Information\n\nIn one sentence, we can describe docker as a hybrid-source application designed to deploy nested-virtual machines that are containerized applications.\nDocker is a powerful tool that can help you develop, deploy, and manage your applications.\nThe Docker build process lets you package your application and all its dependencies into a single image.\nThis image can then be run on any machine that has Docker installed, regardless of the underlying operating system.\nThink of the image as a virtual cd or iso, it has everything needed to run your software wrapped into a single fancy file. \nFinally the image/container makes it easy to deploy your application to any environment, whether it's a local development machine, a cloud server, or a production environment.\nIt's easy to get started with Docker, and you can be up and running in just a few minutes to about a hour if you are a bit noobie.\nRemember that containers are lightweight, isolated environments that make it easy to deploy your applications.\nThey're also portable, so you can run them on any machine that has Docker installed.\nSo docker takes your source code, wraps it all into an image, then runs the image in a virtual machine aka container.\nAlso, in this documentation, we will include more additional tips, such as security and optimization, for your docker adventure. \n\n## Cheatsheet\n\nThis is a quick cheetsheet for Docker, everyone comes back to these sheet for when they run into future problems or forget a certain command. \nIt is not important to understand this cheetsheet until you have a couple sessions of docker delopyment under your belt, so if you are a newbie, do not freak out!\n\n- Basic CLI (Command-line interface)\n  - Container Management Commands\n    - `docker create $image [-command]` - Create a Docker Container based upon the image String; -command for additional flags.\n    - `docker run $image [-command]` - Combines the command `create` and `start`.\n    - `docker start $cont` - Start the specific docker container (defined via cont String).\n    - `docker stop $cont` - Shutdown the specific docker container (defined via cont String).\n    - `docker kill $cont` - Kill the specific docker container (defined via cont String).\n    - `docker restart $cont` - Restart the specific docker container (defined via cont String).\n    - `docker pause $cont` - Pause the specific docker container (defined via cont String).\n    - `docker rm $cont` - Remove the specific docker container (defined via cont String).\n  - Inspecting Containers\n    - `docker ps` - List running docker containers.\n    - `docker ps -a` - List all docker containers, including docker containers that are paused / off.\n    - `docker logs $cont` - Display the specific docker container output (defined via cont String)\n    - `docker top $cont [-ps]` - Display the processes running inside the specific docker container (defined via cont String).\n    - `docker diff $cont` - Show the differences, within the modified files, between the specific container and the source image (defined via cont String).\n    - `docker inspect $cont` - Show information about the specific docker container (defined via cont String).\n      - Output of the data will default to `json`.\n  - Interacting with Containers\n    - `docker attach $cont` - Attach to the specific docker container and see the _stdin, stdout, stderr_ (defined via cont String)\n    - `docker cp $cont:$path $hostpath` - Copy files from the docker container.\n    - `docker cp $hostpath $cont:$path` - Copy files into the docker container.\n    - `docker export $cont` - Export the data of the specific docker container.\n      - Output of the data will default to a `tar` archive.\n    - `docker exec $cont $command` - Runs the $command inside of the specific docker container (defined via cont String).\n    - `docker wait $cont` - Waits until the specific docker container terminates and returns an exit code.\n    - `docker commit $cont $image` - Commits a new docker image via a snapshot of the specific docker container.\n  - Network\n    - `docker network create $netname` - Create a network with the variable $netname.\n  - Docker Compose\n    - `docker compose start` - Start a YAML configuration for a docker container.\n    - `docker compose stop` - Stop the most recent composed docker container.\n    - `docker compose pause` - Pause the most recent composed docker container.\n    - `docker compose unpause` - Unpause the most rencent composed docker container.\n    - `docker compose ps` - List the current docker containers\n    - `docker compose up -f $compose.yml [$command]` - Start and run a YAML configuration for a docker container.\n    - `docker compose down` - Down a composed docker container.\n  - Docker Swarm\n    - `docker swarm init` - The docker container will become a manager node within the initialized container.\n      - Upon the initialization instance, the container will provide a token for other worker/manager nodes to join.\n    - `docker swarm join --token $token $ip` - Docker container will join the swarm as a worker; token string should be obtained by init and the `$ip` should be IP Address and port.\n      - `$ip` will be given as `$$ipaddress:$$port` , where the substring `$$ipaddress` is the IPv4address or IPv6address and the substring `$$port` is the open port on that `$$ipaddress`.\n  - Docker Prune / Clean up\n    - `docker system prune` - The docker system will clean up any dead objects, such as containers, networks, ect..\n      - `docker system prune -a` - Incase you need to do a deep clean within the docker node.\n\n---\n\n## DockerFile\n\n- The `DockerFile` is a simple document that assembles the docker image using a specific base and a set of commands.\n- The idea being that the docker image is an isolated operating system for the specific application, with all the libraries required to be pre-install / pre-built.\n\n- ### FROM\n\n  - There are 3 generic ways to use `FROM` :\n    - `FROM {image}`\n    - `FROM {image}:{tag}`\n    - `FROM {image}@{digest}`\n      - The `{image}` would be the base image title / reference.\n      - The `{tag}` would be the version tag, if a specific version is required, such as `node:16` or `node:16-bullseye`\n      - The `{digest}` would be the `sha-256` hash, used to verify the integrity of the application.\n\n- ### MAINTAINER\n\n- ### RUN\n\n- ### CMD\n\n- ### LABEL\n\n- ### ENV\n\n- ### ADD\n\n- ### COPY\n\n- ### ENTRYPOINT\n\n- ### VOLUME\n\n- ### USER\n\n- ### WORKDIR\n\n- ### ARG\n\n- ### ONBUILD\n\n- ### STOPSIGNAL\n\n  - The `STOPSIGNAL` sets the system call signal that would stop the container / application from running.\n  - The default setting is to send `SIGTERM` and wait for 10s to gracefully shutdown the then send the `SIGKILL`.\n\n- ### HEALTHCHECK\n\n  - The concept of `HEALTHCHECK` is to provide the `health` of the container, letting the swarm or manager know the general status of the operating application.\n  - The two main terms within the `HEALTHCHECK` are `healthy` and `unhealthy`\n\n---\n\n## GPU\n\n- Windows\n  - GPU pass-through is still in the experimental stage but here are some quick ways to get the basics going.\n  - We are assuming that you have WSL on the windows instance. [For WSL Help](https://kbve.com/application/wsl/)\n    - Nvidia\n      - Install the latest CUDA driver libraries from their official website. [Nvidia CUDA](https://developer.nvidia.com/cuda-downloads)\n      - If the latest core that you installed was\n\n---\n\n## Setup\n\nDocker is the future of application development because of how fast, easy and portable the software is.\nIn this section of the document, we will focus on setting up the application on various operating systems, including linux, windows and mac.\nWith Docker, you can build, deploy, and manage your applications in a fraction of the time it would take with traditional methods.\nIf you're not using Docker, you're missing out. \nSo what are you waiting for homie!? \nLet us begin the setup quest for Docker today!\n\n\n### Install\n\nThis section breaks down the various areas of installing `docker`.\nTo install Docker, simply visit the Docker website and download the installer for your operating system. \n\n#### Linux\n\nThe operating sysetm that we perfer is `Ubuntu` and here is a quick and brief tutorial:\n\n- Ubuntu Installation Guide\n  - Core Pre-Installation\n    - `lsb_release -a` - Unix command to see the version of Ubuntu that we are running.\n    - According to Docker (2022), these are the 64-bit versions of Ubuntu that they support.\n      - `Ubuntu Jammy 22.04 (LTS)`\n      - `Ubuntu Impish 21.10`\n      - `Ubuntu Focal 20.04 (LTS)`\n      - `Ubuntu Bionic 18.04 (LTS)`\n    - Hint: We like to make sure everything is updated and upgraded before we start. So run `sudo apt-get update` and then `sudo apt-get upgrade`.\n    - Now there are libraries that you will need before installing docker.\n  - Post Installation\n    - Adding Docker Compose through `sudo apt-get install docker-compose-plugin`, you may need to update before installing.\n    - Verifying the installation through `docker compose version` and if there are any issues, visit our support.\n\n\n#### Windows\n\nBefore we being our journey on setting up `Docker` onto Windows, you will have to make sure that WSL is installed and ready.\nFurthermore, you may need to enable the Hyper-V through your bios.\n\nThe best way to setup `Docker` is by installing the engine through `Choco` because it will help keep the engine up to date.\n\n\n---\n\n\n## Guides\n\nAdditional guides for docker and reference material will be here.\n\n\n## Media\n\nWe will include some YT videos here in the future for people to watch! \nI believe I will also make a small session video later on from setting up docker from scratch.\n\n\n---\n\n## Errors\n\nWe will try to document all the errors that we face within Docker!\nSometimes there are just so many and it can be a pain to shift through them all.\n\n\n---\n\n## Notes\n\n- Docker Output JSON (helpful for debugging)\n  - `result=$(curl --unix-socket /var/run/docker.sock http://localhost/containers/json --silent 2>&1) && echo $result`\n    - This will grab the current docker-instance information and return it in JSON format.\n- Docker notes will be added for later reference\n\n---\n\n### Roadmap\n\n- Official Roadmap from Docker\n  - [Roadmap](https://github.com/docker/roadmap/projects/1)\n\n---\n\n### WASI\n\nOfficial Notes for the [Beta Desktop](https://docs.docker.com/desktop/wasm/)\n\nI am still test casing it locally, one of the cool aspects would be to run Edge WASI/WASM through Portainer.\n\n","collection":"application","data":{"title":"Docker","description":"A hybrid-source application designed to deploy nested-virtual machines that are containerized applications.","tags":["vm","host","docker","container"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1605745341112-85968b19335b?fit=crop&w=1400&h=700&q=75"}},{"id":"flipperzero.mdx","slug":"flipperzero","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n\n<TabMenu first=\"general\" data={[ \"guides\", \"media\", \"notes\"]}>\n<TabData tail=\"block\" data=\"general\">\n\n## Information\n\nFlipper Zero is a portable multi-tool device for geeks that can interact with various digital systems in real life, such as RFID, radio protocols, access control systems and more.\nIt gives you full access to its source code and design, so you can tailor it to your own needs and preferences.\nYour cyber-buddy, Flipper Zero, is a cybernetic companion with a Tamagotchi-like personality that enjoys exploring and manipulating digital and analog systems.\n\n> Please be responsible with your usage of this dangerous dolphin xD\n\n<Details data=\"Metaphor for FlipperZero\">\n\n### FlipperZero Metaphors\n\nFlipper Zero is a magic wand for digital mischief.\n\n</Details>\n\n<Details data=\"ELI5 for FlipperZero\">\n\n### Explaining Flipprzero to a 5 year old!\n\nFlipper Zero is a small toy that looks like a dolphin. \nIt can talk to other toys and machines using invisible waves. \nIt can also copy what they say and pretend to be them. \nYou can use Flipper Zero to play games and learn new things. \nYou can also make it do what you want by changing its code. \nFlipper Zero is very smart and friendly, but you have to be careful not to use it for bad things.\n\n</Details>\n\n* * *\n\n## Firmware\n\n> The bundles of joy when installing various firmware for your flipperzero!\n> The main chipset on the FlipperZero stores both a \"New\" and \"Old\" firmware, thus making it a bit easier to custom load your firmware without the higher risk of bricking your device. Granted there is always a risk of bricking your device, so be very careful! Make sure wires are tight and your machine is charged.\n\nFirmware is the software that powers your Flipper Zero and lets you enjoy its amazing capabilities and control its functions and features. \nWe will teach you how to update your firmware, thus keeping your device fresh and flawless with new improvements and fixes.\nThere are different types of firmware for Flipper Zero, such as the official firmware, the release candidate firmware, the dev firmware, and the custom firmwares. \nThe official firmware is the stable version that is tested and approved by the Flipper team. \nThe release candidate firmware is the next version that is being tested before it becomes official. \nFinally the dev firmware is the latest version that has new features and changes, but it may have bugs and errors. \nIn addition, there are custom firmwares made by other users who want to modify or add something to the Flipper Zero, which we will go over later down in this document.\nYou can choose which firmware you want to use and install it using the Flipper Mobile App or the qFlipper desktop application, with more information in the #update section.\n\n* * * \n\n### Install\n\n* * *\n\n### Update\n\nOnce you get your hands on the flipperzero, we recommend that you update it to the latest firmware via qFlipper application, links below:\n\n[Official Main](https://flipperzero.one/update) Updates\nGithub Repo Updates - [Release Page](https://github.com/flipperdevices/qFlipper/releases)\n\nThere are other methods of updating, including Mobile and Web but from experience, I recommend sticking with a direct cable upgrade, to avoid possible firmware corruption.\n\n### Custom\n\nCustom firmwares are special versions of software that let you customize your Flipper Zero and unlock new possibilities. \nThey are made by creative and talented users who want to share their ideas and innovations with the Flipper community. \nYou can try different custom firmwares and see what they can do for your device!\nWe hope you find the best custom firmware to fit your needs and we recommend having multiple SD Cards with each custom firmware, so you can swap easily.\n\n#### Unleashed Firmware\n\nOfficial [Repo](https://github.com/DarkFlippers/unleashed-firmware)\n\nForked Unleashed Firmware include:\n\n[RogueMaster](https://github.com/RogueMaster/flipperzero-firmware-wPlugins)\n[v1nc](https://github.com/v1nc/flipperzero-firmware)\n\nWe will add KBVE's custom firmware in 2023.\n\n#### KBVE Firmware\n\nOur firmware is currently a private fork of Unleashed and will contain more custom HTTP/Networking additions, making it easier to operate the device in isolation and/or remote instances.\n\n* * *\n* * *\n* * *\n\n## GHz\n\n- The frequencies that FlipperZero operates in are `300-348 MMHz`, `387-464 MHz` and `770-928 MHz` bands through the `CC1101` chipset. \n\n- ### GHz Sub Menu\n\n  - `Read` - Reads & decodes the signal of the protocol within the frequency range.\n    - Lower left side will display the current frequency.\n    - Lower right side will display the remaining slots of scanned signals.\n  - `Read RAW` - Records the radio signal in RAW format.\n    - Requires a microSD for the storage of the RAW.\n  - `Saved` -\n  - `Add Manually` -\n  - `Frequency Analyzer` -\n\n#### GHZ InfoSec\n\n- 315Ghz - Common frequency that car fobs operate in.\n\n## GUI\n\nTo help with designing the GUI, we recommend checking out `Flipper UI` , which is an amazing tool for quick edits.\nSource for it can be found here : [FUI-EDITOR](https://github.com/sbrin/ilin.pt/tree/main/_stuff/fui-editor)\n\n## NFC\n\nThese are notes on the `NFC` aspect of the device.\n\n### FlipperZero NFC\n\n- NFC (13.56 MHz) module can read, save and emulate NFC cards / frequencies.\n- NFC is known as near-field communication and operates at the 13.56 MHz (which is  an unlicensed radio frequency ISM band under the ISO/IEC 18000-3).\n- Menu\n  - -> `Read` - Read && Save NFC data, including, UID, ATQA, SAK and storage data.\n  - -> `Detect Reader` - Emulation of an NFC card to grab information related to authentication keys from logs sent by a reader.\n  - -> `Saved` - Saved NFC cards on the device, which can be emulated.\n  - -> `Extra Actions` - Commands for extra functionality through custom scripts, plugins, applications on the device.\n  - -> `Add Manually` - Create an NFC card by adding the data manually.\n- NFC Terms\n  - -> `UID` is a read-only unique identifier for the specific NFC chip.\n- NFC-V\n  - Currently does not fully support ISO 15693.\n\n## pyFlipper\n\nThis is an unofficial cli wrapper for the Flipper Zero device and we will integrate it with our current eco-system, including the possible future expansion into our core IoT project.\n\n</TabData>\n\n<TabData data=\"guides\">\n\n## Guides\n\nWe definitely need more guides on the FlipperZero.\n\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n## Notes\n\nKBVE FlipperZeros will be sold for $300 each, custom firmware, extra components, shipping and 5 support tickets? \n$180 for the Flipper Zero and $120 for services/software/extras/labor.\n\n* * *\n\n### Log\n\nThis is log collection for the KBVE MDX document on FlipperZero.\nRemember Flipper Zero is a revolutionary device that enables anyone to hack the matrix.\n\n#### Journal\n\n<Details data=\"2023-04-16\">Adding tabs to the FlipperZero MDX.</Details>\n<Details data=\"2023-04-10\">We need to add some more information for 3rd party flipper firmware.</Details>\n\n</TabData>\n</TabMenu>","collection":"application","data":{"title":"FlipperZero","description":"Flipper Zero is a pen test multi-tool! Think of it as a Swiss Army knife for wireless hacking.","tags":["hacks","redteam","nfc"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1525826212383-92e29530133e?fit=crop&w=1400&h=700&q=75"}},{"id":"flutter.mdx","slug":"flutter","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n\n<TabMenu first=\"general\" data={[ \"guides\", \"media\", \"notes\"]}>\n<TabData tail=\"block\" data=\"general\">\n\n## Information\n\n> TLDR; Flutter is an open source cross platform development kit.\n\nFlutter is a software development kit created by Google that allows developers to build beautiful and natively compiled applications for almost any platform - mobile (Android and iOS), web (any browser) and desktop (Windows, Mac, Linux) all from a single codebase. \nFlutter is often used with DART, which is an object-oriented programming language by Google. \nThe biggest advantage of flutter is that it can be used to create cross-platform applications. \nSo, if you want to build an app that looks stunning and works great on any device, Flutter is the way to go! 😊\n\n\n* * *\n\n## Install\n\nInstallation is broken down into two different aspects, the first aspect is within the core of flutter and the other aspect contains the scopes.\n\n### Windows\n\nYou can install Flutter on Windows by following these steps:\n\n1. Navigate to flutter.dev on your webpage.\n2. On the top menu bar, select Docs > Get Started > Install > Windows.\n3. Check for the System Requirements.\n4. Download the Flutter SDK.\n5. Extract the zip file and place it in your desired location.\n6. Add Flutter to your path.\n7. Run `flutter doctor` to verify that Flutter has been installed correctly.\n\n\n\n* * *\n\n## Cheatsheet\n\n- Healthcheck\n  - `flutter docker`\n- Flutter upgrade\n  - `flutter upgrade`\n- Package Get\n  - `flutter packages get`\n  - `flutter pub get`\n  - Flutter will download and save the packages locally.\n- List all devices for flutter.\n  - `flutter devices`\n- Run application on a specific device.\n  - `flutter run -d {$device} -v`\n- Flutter logs from the specific device.\n  - `flutter logs -d {$device`\n- Flutter clean\n  - `flutter clean`\n  - The command deletes all temporary folders and builds.\n- Fluter cache\n  - `flutter pub cache repair`\n- Package removal.\n  - `flutter pub remove {$package}`\n- Package add / install\n  - `flutter pub add {$package}`\n\n* * *\n\n## Packages\n\n[Pub.dev](https://pub.dev) is the official package repository for Dart / Flutter apps! However we will show you how to add your own custom packages as well.\n\n### Markdown\n\nWe have two packages that we are currently looking into for markdown / md files, however we were not able to find a solution yet to render full MDX / Markdown Javascript.\n\n</TabData>\n\n\n<TabData data=\"guides\">\n\n## Guides\n\n\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Notes\n\nOur official notes for the Flutter MDX.\n\n### Log\n\n- [ ] Add Media for Flutter.\n- [ ] Under guides, we could include links to exisiting courses for Flutter.\n\n#### Journal\n\n##### 2023-04-10\n\n</TabData>\n</TabMenu>","collection":"application","data":{"title":"Flutter","description":"Open-source cross platform UI/UX software development kit based upon Dart and created by Google.","tags":["technology","software","dart","flutter"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1628277613967-6abca504d0ac?fit=crop&w=1400&h=700&q=75"}},{"id":"gcloud.mdx","slug":"gcloud","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n<TabMenu first=\"general\" data={[\"guides\", \"media\", \"notes\"]}>\n\n<TabData tail=\"block\" data=\"general\">\n\n## Information\n\n## GCloud Compute\n\n- GCloud Compute Guide is still a work in progress; these are active notes from my current R&D.\n  - ```shell gcloud compute --help```\n    - This will display all of the commands that will help you utilize the `compute engine`.\n\n- The are split into two major concepts, with `GROUP` and `COMMAND`.\n  - According to Google, the compute command helps create, configure and manipulate the virtual machines within your pre-set project.\n  - The `SYNOPSIS` is `gcloud compute GROUP | COMMAND [GCLOUD_WIDE_FLAG ...]`\n\n## GCloud Compute Load Balancer\n\n- Command to run 3 instances of `nginx` with an ingress load balancer.\n  - Shell command for VM that is running nginx inside of a `debian` operating system.\n\n    - ```shell\n             gcloud compute instances create www-server-1 \\\n                --zone=us-west1-b \\\n                --tags=network-lb-tag \\\n                --machine-type=e2-medium \\\n                --image-family=debian-11 \\\n                --image-project=debian-cloud \\\n                --metadata=startup-script=start_nginx.sh\n        ```\n\n      - start_nginx.sh ->\n\n        - ```shell\n                            #!/bin/bash\n                            apt-get update\n                            apt-get install nginx -y\n            ```\n\n      - For switching from Nginx to Apache2, replace the `nginx` with `apache2`.\n      - To check the status on `ubuntu`, run the `sudo systemctl status nginx` OR `sudo systemctl status apache2`.\n\n    - Example of a Load Balance Template:\n      - The shell below is an example of an instance template that creates the load balance backend template.\n\n        - ```shell\n              gcloud compute instance-templates create lb-backend-template \\\n              --region=us-west1 \\\n              --network=default \\\n              --subnet=default \\\n              --tags=allow-health-check \\\n              --machine-type=e2-medium \\\n              --image-family=debian-11 \\\n              --image-project=debian-cloud \\\n              --metadata=startup-script=start_nginx_script.sh\n              ```\n\n      - Key concept is : Managed instance groups MIGs\n        - Mage instance groups or MIGs enable you to operate applications on multiple identical / clone virtual machines, thus allowing your orchestration to become scalable and highly available. This is done by utilizing the components within the automated MIG services, which includes: autoscaling, autohealing, regional (multiple zone) deployment, and automatic updating.\n    - Manage Instance Group for the load balancer:\n\n      - ```shell\n            gcloud compute instance-groups managed create lb-backend-group \\\n            --template=lb-backend-template --size=2 --zone=us-west1-b \n          ```\n\n      - Health Check:\n\n      - ```shell\n            gcloud compute firewall-rules create fw-allow-health-check \\\n            --network=default \\\n            --action=allow \\\n            --direction=ingress \\\n            --source-ranges=130.211.0.0/22,35.191.0.0/16 \\\n            --target-tags=allow-health-check \\\n            --rules=tcp:80\n            ```\n\n      - Backend-Services for gcloud compute\n\n        - ```shell\n\n            gcloud compute backend-services create web-backend-service \\\n                --protocol=HTTP \\\n                --port-name=http \\\n                --health-checks=http-basic-check \\\n                --global\n\n            ```\n\n          - Add Instance Group as the Backend to the Backend Service:\n\n            - ```shell\n                    gcloud compute backend-services add-backend web-backend-service \\\n                --instance-group=lb-backend-group \\\n                --instance-group-zone=us-west1-b \\\n                --global\n                ```\n\n          - Create a URL Map for routing the requests to the default backend services.\n\n            - ```shell\n                    gcloud compute url-maps create web-map-http \\\n                    --default-service web-backend-service\n                    ```\n\n            - Extra information regarding the URL Map:\n                    *** Note: URL map is a Google Cloud configuration resource used to route requests to backend services or backend buckets. For example, with an external HTTP(S) load balancer, you can use a single URL map to route requests to different destinations based on the rules configured in the URL map:\n                        Requests for [Video](https://example.com/video) go to one backend service.\n                        Requests for [Audio](https://example.com/audio) go to a different backend service.\n                        Requests for [Images](https://example.com/images) go to a Cloud Storage backend bucket.\n                        Requests for any other host and path combination go to a default backend service.\n            - Create a target HTTP proxy to route requests:\n\n              - ```shell\n                        gcloud compute target-http-proxies create http-lb-proxy \\\n                        --url-map web-map-http\n                ```\n\n            - Global forwarding rule to route incoming requests to the proxy:\n\n              - ```shell\n                        gcloud compute forwarding-rules create http-content-rule \\\n                        --address=lb-ipv4-1\\\n                        --global \\\n                        --target-http-proxy=http-lb-proxy \\\n                        --ports=80\n                ```\n\n## Google Rules\n\n### Google Forwarding Rules\n\nNote: A forwarding rule and its corresponding IP address represent the frontend configuration of a Google Cloud load balancer. Learn more about the general understanding of forwarding rules from the Forwarding rule overview Guide.\n\n[Using Forwarding Rules](https://cloud.google.com/load-balancing/docs/using-forwarding-rules)\n[Rule Concepts](https://cloud.google.com/load-balancing/docs/forwarding-rule-concepts)\n\n</TabData>\n\n<TabData data=\"guides\">\n\n## Guides\n\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Notes\n\n### Log\n\n#### Journal\n\n<Details data=\"2023-04-16\">Updated GCloud with tabs. </Details>\n\n</TabData>\n</TabMenu>","collection":"application","data":{"title":"GCloud","description":"GCloud is a Command Line Interface that designs, builds and scales Google Cloud resources.","tags":["google","gcloud","cloud"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1498354136128-58f790194fa7?fit=crop&w=1400&h=700&q=75"}},{"id":"git.mdx","slug":"git","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n<TabMenu first=\"general\" data={[\"guides\", \"media\", \"notes\"]}>\n\n<TabData tail=\"block\" data=\"general\">\n\n## Git\n\nEverything you will need to prepare for git!\n\n---\n\n## Github\n\n### Github Notes\n\nThese are the notes for utilizing Github at an organizational level, with links/reference point to various modules/actions within the github eco-system.\n\n### Github Labels\n\nKBVE Default Labels are located [here](https://github.com/organizations/KBVE/settings/repository-defaults) , referenced as, `https://github.com/organizations/KBVE/settings/repository-defaults` , swap out `KBVE` with your organizational slug.\n\n### Github Actions\n\nGithub Actions are yaml files that help automate repetitive tasks with low-level intelligence / variables.\n\n#### Github Itch\n\nGithub Action - Itch.io Publish\n\n- Marketplace [Action](https://github.com/marketplace/actions/itch-io-publish)\n- Dev [Repo](https://github.com/KikimoraGames/itch-publish)\n\nExample Github Itch Workflow:\n\nKikimoraGames Example YAML:\n\n```yaml\nname: Itch Deploy\n\non: push\nenv:\n  ITCH_USERNAME: my-itch-username\n  ITCH_GAME_ID: my-itch-game-id\njobs:\n  deploy:\n    name: Upload to Itch\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: true\n      matrix:\n        channel:\n          - windows\n          - webgl\n    runs-on: ubuntu-latest\n    name: Deploy - Itch.io ${{ matrix.template }}\n    steps:\n      - uses: actions/download-artifact@v2.0.8\n        with:\n          name: ${{ matrix.channel }}\n          path: build/${{ matrix.channel }}\n      - uses: KikimoraGames/itch-publish@v0.0.3\n        with:\n          butlerApiKey: ${{secrets.BUTLER_API_KEY}}\n          gameData: ./build/${{ matrix.template }}\n          itchUsername: ${{env.ITCH_USERNAME}}\n          itchGameId: ${{ env.ITCH_GAME_ID }}\n          buildChannel: ${{ matrix.channel }}\n          buildNumber: ${{ needs.version.outputs.version_hash }}\n\n```\n\nRemember to add your secrets, `BUTLER_API_KEY`, before deploying to Itch.\nYou can grab the `BUTLER_API_KEY` from Itch via [API Keys](https://itch.io/user/settings/api-keys) , which will allow Github Actions to communicate with Itch.io's API.\n\nKBVE Example:\n\n```yaml\nname: Itch KBVE Deploy\n\non: push\nenv:\n  ITCH_USERNAME: kbve\n  ITCH_GAME_ID: my-itch-game-id\njobs:\n  deploy:\n    name: Upload to Itch\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: true\n      matrix:\n        channel:\n          - windows\n          - webgl\n    runs-on: ubuntu-latest\n    name: Deploy - Itch.io ${{ matrix.template }}\n    steps:\n      - uses: actions/download-artifact@v2.0.8\n        with:\n          name: ${{ matrix.channel }}\n          path: build/${{ matrix.channel }}\n      - uses: KikimoraGames/itch-publish@v0.0.3\n        with:\n          butlerApiKey: ${{secrets.BUTLER_API_KEY}}\n          gameData: ./build/${{ matrix.template }}\n          itchUsername: ${{env.ITCH_USERNAME}}\n          itchGameId: ${{ env.ITCH_GAME_ID }}\n          buildChannel: ${{ matrix.channel }}\n          buildNumber: ${{ needs.version.outputs.version_hash }}\n```\n\n### Github Unity Test Runner\n\nHere is the Game-CI Test Runner updated to v2.1.0, the notation/tab spacing might be off.\n\n```yaml\n\n- uses: game-ci/unity-test-runner@v2.1.0\n    id: testRunner\n    env:\n        UNITY_LICENSE: ${{ secrets.UNITY_LICENSE }}\n    with:\n        projectPath: ${{ matrix.projectPath }}\n        unityVersion: ${{ matrix.unityVersion }}\n        githubToken: ${{ secrets.GITHUB_TOKEN }}\n        customParameters: '-nographics'\n- uses: actions/upload-artifact@v2\n        if: always()\n        with:\n            name: Test results (all modes)\n            path: ${{ steps.testRunner.outputs.artifactsPath }}\n\n```\n\n### Github GoDot Actions\n\n- Github Actions via [godot-ci](https://github.com/marketplace/actions/godot-ci)\n- Github Actions HTML5 Workflow [Gist by doctor-g](https://gist.github.com/doctor-g/57cd32c10beb04fcbd3b83f23f439d37)\n\n---\n\n## GitLab\n\n### Gitlab Information\n\n---\n\n## Plastic SCM\n\nFor Plastic SCM / Git Integration, we will be using Plastic SCM's Git Server `https://www.plasticscm.com/gitserver`.\n\n```php\n-------------------------\ntcp.port=9418\nexport.repo=quake\n-------------------------\n```\n\n---\n\n## SubModules\n\nThese are notes and guides on how to build out submodules inside of Git, so that you can control certain plugins throughout multiple repos effortlessly. This can go into private packages later on, if we need to.\n\nThe shift to the private packages will come as we grow bigger and require more control.\n\n### Submodule Symbolic Link\n\nThese are notes on how to symbolic link multiple directories without having to run into issues.\n\n#### KBVE Module Example\n\nSuppose we have already added our submodule for an Unity project, via `KBVE/UnitySubModule` and wanted to link them into our source, well this is how:\n\nCreate a folder inside of `Assets` named `Plugins` and then cd into it:\n\nExample of the shell, do not copy and paste, make sure you read through the commands and swap out the right variables!\n\n```shell\ncd ./unityRootProject\ncd ./Assets\nmkdir Plugins\ncd ./Plugins\n\n```\n\nOnce inside the `Plugins` folder, we can execute the symbolic link using the `ln` command, like this:\n\n```shell\n\nln -s ../../submodules/UnitySubModules/Vuplex\n\n```\n\n---\n\n</TabData>\n\n<TabData data=\"guides\">\n\n## Guides\n\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Notes\n\n### Log\n\n#### Journal\n\n<Details data=\"2023-04-16\"> Added tabs to the GIT MDX. </Details>\n\n</TabData>\n</TabMenu>","collection":"application","data":{"title":"Git","description":"Git - This is gonna take a while!","tags":["software","git"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1618401479427-c8ef9465fbe1?fit=crop&w=1400&h=700&q=75"}},{"id":"godot.mdx","slug":"godot","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n<TabMenu first=\"general\" data={[\"guides\",\"demos\", \"media\", \"notes\"]}>\n\n<TabData tail=\"block\" data=\"general\">\n\n## Information\n\nGoDot is a free and open source game engine that offers a unique and innovative way to create 2D and 3D games for various platforms, using a node and scene system, multiple programming languages, and a community-driven development model.\n\n</TabData>\n\n<TabData data=\"guides\">\n\n## Guides\n\n- GoDot Export as HTML5 [Tutorial](https://docs.godotengine.org/en/stable/tutorials/export/exporting_for_web.html)\n- Exporting Template for Platforms missing [Error Guide](https://godotengine.org/qa/65015/export-templates-for-this-platform-are-missing)\n\n</TabData>\n\n<TabData data=\"demos\">\n\n## Demos\n\n- GDQuest Repo of GoDot [Demos](https://github.com/GDQuest/godot-demos)\n\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Notes\n\n### Log\n\n#### Journal\n\n<Details data=\"2023-04-16\">Updated GoDot with tabs. </Details>\n\n</TabData>\n</TabMenu>\n","collection":"application","data":{"title":"GoDot","description":"GoDot is a cross-platform and open source game engine written in GDScript, C# and C++.","tags":["software","godot","game-engine"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1605347086577-706b21474ed7?fit=crop&w=1400&h=700&q=75"}},{"id":"javascript.mdx","slug":"javascript","body":"\nimport BlockQuote from \"@mdx/BlockQuote.astro\";\n\n## Javascript\n\nJavaScript / JS is a cross-platform object-oriented computer programming language that was originally designed to add interactivity and functionality to web content. \nOver the years, it has evolved into an industry leading collection of libraries, packages and frameworks, which are used to create websites that are lively and engaging, as well as applications, games, and more.\n\n* * *\n\n## Info\n\nIf you are a web developer or a web enthusiast, you have probably heard of JavaScript! Or why else would you be here?. \nBut what exactly is JavaScript?!, and why is it so dominant in web and application development?! \nSuppose you had the ability to create a web page, game or application that can change its appearance based on the time of day, the weather, or the user's preferences. \nThink of how amazing it would be if you could add interactive elements such as buttons, forms, sliders, or quizzes to your web page without reloading it. \nEnvision what it would be like to create stunning animations and graphics that make your web page stand out from the crowd. \nJavaScript is the one true king of the web, and it can work wonders with minimal code. Whether you want to create dynamic websites, interactive games, or powerful apps, JavaScript can make it happen.\nIn this eye-opening document, we will give you a brief overview of JavaScript, its history, its features, and its applications. \nYou will learn how JavaScript can make your web pages more dynamic and interactive, and how it can help you create stunning web applications that run in the browser. \nPrepare to unleash the power of JavaScript with this mdx documentation. \nYou will learn everything you need to create dynamic and interactive web applications from scratch. \nWhether you are a beginner or a seasoned coder, this guide will take your skills to the next level.\n\n* * *\n\n## Design\n\nWould you like to learn how to write JavaScript code that is clean, clear, and consistent?\nDo you have a passion and desire to solve common problems in software design with ease and elegance? \nHow would you like to master JavaScript and dazzle your peers and clients with your brilliant code?\nDid any of these questions resonate with you?\nIf that rings a bell, you’ve hit the jackpot by coming to this resource!\nWe will introduce you to the power and beauty of `design patterns` and how they can enhance and transform your work.\nDesign patterns are reusable solutions that help you organize your code, simplify your logic, and communicate your intent. \nThey are like recipes or templates that you can use to cook up delicious and nutritious code for your app. \nYou will learn about some of the most common and useful design patterns in JavaScript, such as creational, structural, and behavioral patterns. \nYou will also see some real-world examples of how these patterns can make your code more efficient, maintainable, and readable. \nBy the end of this documentation, you will have a better understanding of design within JavaScript and how to apply it to your own projects. \nAnd as a bonus, KBVE will also share with you some of the best resources and tools to learn more about design patterns and practice them in your own code. \nSo do not miss this opportunity to become a better JavaScript developer! \nRead on, discover the secrets of design patterns and experience the magic and potential of design patterns for yourself below.\n\n### Design Patterns\n\nThe theory of javascript design patterns can be classified into three major categories, namely creational, structural, and behavioral patterns. \nThese classes differ from each other in various distinctions and aspects, such as how complex and elaborate the pattern is, the level of detail it offers to the developer and end-user, and the scope of its impact on the system being designed.\nUnderstanding these divisions can help developers choose the most suitable design pattern for their specific needs and goals within the application, interface or project.\n\n#### Creational Design Patterns\n\nCreational patterns enable a more adaptable and reusable code by offering a flexible framework for creating objects or classes. \nIn this nature, the design shields the users from the complex construction process and streamline their interaction with the classes.\nThus, the pattern controls the user-class interaction and save the developers from handling complex construction.\n\nFactories, builders and singletons are the three core concepts of creational design pattern.\n\n##### Abstract Factory\n\nThe `Abstract Factory` concept is a component within creational design pattern that provides an interface for creating families of related or dependent objects without specifying their concrete classes. \nThis concept is advantageous when a system or application requires the versatility of handling diverse objects that share a thematic connection, or in other words, the system needs to work with multiple types of objects that are related by a common theme.\n\nTo exemplify, envision that a developer is working on a cross-platform application that requires generating user interface components, such as buttons, modals, forms, text boxes, and menus.\nThe programmer would utilize an `Abstract Factory` to define an interface for creating and rendering these UI elements. \nThen, the developer could have different concrete factories that implement this interface to create UI building blocks for different platforms (e.g., Windows, Android, iOS, MacOS, Linux).\nAs a result, the rest of your application codebase can remain the same and doesn’t need to know the details of how the UI/UX elements are created for each platform. \nInstead, the application or software can just use the factory interface to create the UI features it needs, thus optimizing productivity and resources.\n\n##### Builder\n\n##### Singleton\n\n#### Structural Design Patterns\n\nStructural Design Patterns, SDP, are concerned with how objects and classes are composed to form larger structures. \nThey help to ensure that changes in one part of the system do not affect other parts.\n\n#### Behavioral Design Patterns\n\nBehavioral Design Patterns, BDP, define the communication between objects and how they interact with each other. \nThey help to ensure that objects work together in a coordinated manner.\n\n### UXUI\n\nCollection of design libraries and frameworks for your javascript applications.\n\n#### MUI\n\nMaterial UI, which is a library of UI components for Javascript applications that follows Googles design guidelines.\n\n#### TailWindCSS\n\nTailWindCSS or Tailwind is a custom open source CSS framework written in Javascript that enables utility css classes.\n\n##### TailWindCSS Install\n\nSince the core of TailWind is written in NodeJS, you can install it via `npm` || `yarn` || or any node package management software.\n\n##### TailWindCSS Config\n\nThe default name for the configuration file is `tailwind.config.js` or `tailwind.config.cjs` and the default location is within the root of the project.\n\n##### TailWindCSS Animation\n\nAnimation Utility provides animating elements, which can be extended and abstractly layered through Rive/Lottie.\n\nThe default animations are:\n\n`animate-spin` : Which uses a keyFrames spin to transform / rotate the object, primary use case is for loading indictions.\n`animate-ping` : Uses transform to slowly scale out the element and create a radar / ripple effect upon the element, primary use case is for notifications.\n`animate-pulse` : Alter the opacity of the element, to create a fading in and out effect, primary use case is for skeleton loaders.\n`animate-bounce` : Transform the Y access of the element. primary use case is for aesthetics.\n`hover:$animation` : Conditional statement, where if the mouse is over the element, perform the animation.\n\n###### Spin-Slow\n\nThis is a custom animation that you can add to TailWindCSS by extending the animations field within the configuration file.\n\nScoped: `animation: { 'spin-slow': 'spin 5s linear infinite',  }`\n\nProof of Concept:\n\n```javascript\n/** @type {import('tailwindcss').Config} */\n  module.exports = {\n    theme: {\n        extend: {\n            animation: {\n                'spin-slow': 'spin 5s linear infinite',\n            },\n        },\n    },\n  }\n```\n\n* * *\n\n## Bun\n\n- Bun is a batteries-included runtime engine that bundles, transpiles, installs and runs Javascript / typescript with a task runner.\n\n### Bun Install\n\n- CLI for MacOS, Linux and Windows (through WSL)\n\n  - ```shell\n        curl https://bun.sh/install | bash\n    ```\n\n- Homebrew for MacOS / Linux\n  \n  - ```shell\n        brew tap oven-sh/bun\n        brew install bun\n    ```\n\n- Docker\n  - Bun recommends using the `jarredsumner/bun:edge` build as the Docker base.\n\n    - ```shell\n        docker pull jarredsumner/bun:edge\n        docker run --rm --init --ulimit memlock=-1:-1 jarredsumner/bun:edge\n        ```\n\n  - Example of Docker build:\n\n    - ```shell\n        FROM jarredsumner/bun:edge\n        WORKDIR /app\n        COPY package.json package.json\n        COPY bun.lockb bun.lockb\n        RUN bun install\n        COPY . .\n        EXPOSE 3000\n        ENTRYPOINT [\"bun\", \"index.js\"]\n        ```\n\n      - Remember to double check the working directory variable : `WORKDIR /app`\n      - Make sure the port `3000` is the one being used by your application.\n      - Ensure that `index.js` is the start of your application.\n\n### Bun Upgrade\n\n- CLI\n  - Latest Version\n\n    - ```shell\n        bun upgrade\n      ```\n\n  - Canary Version\n\n    - ```shell\n        bun upgrade --canary\n        ```\n\n### Bun Commands\n\nQuick cheatsheet on the general commands for `bun`.\n\n#### Bun Run\n\nThis will execute the script (Javascript / Typescript) within the runtime engine.\n  \n```shell\nbun run\n```\n\nThis should replace `npm run` with `bun run`.\n\n#### Bun Clean\n\nTo remove the cache:\n\n```shell\nbun run clean\n```\n\n#### Bun Hot\n\nHot Reload : Bun will live reload the application, similar to file watchers like nodemon.\n\n```shell\nbun run --hot index.ts\n```\n\n#### Bun Dependencies Install\n\nThis will install the dependencies for the application using an extremely fast npm-compatible package manager.\n\n```shell\nbun install\n```\n\nThis should replace `yarn install` or `npm install` with `bun install`\n\n#### Bun Flags\n\nThis chart is from the official documentation.\n\n| Flag         | Description                            |\n| ------------ | -------------------------------------- |\n| --npm        | Use `npm` for tasks & install          |\n| --yarn       | Use `yarn` for tasks & install         |\n| --pnpm       | Use `pnpm` for tasks & install         |\n| --force      | Overwrite existing files               |\n| --no-install | Skip installing `node_modules` & tasks |\n| --no-git     | Don’t initialize a git repository      |\n| --open       | Start & open in-browser after finish   |\n\n* * *\n\n## AstroJS\n\n### Astro\n\n- Astro is an island architecture style static website generator that enables fast, powerful and multi-framework site.\n\n### Astro Svelte\n\nSvelte is an amazing way to create brilliant UX/UI that is extremely fast within the framework of Astro.\n\nMore information on [Svelte](https://kbve.com/application/javascript/#svelte)\n\n#### Astro Svelte Render\n\nAn example of calling or rendering Svelte objects inside of Astro with a slot:\n\n```html\n\n<Object client:only=\"svelte\">\n<!-- Slot -->\n</Object>\n\n```\n\nWithout a slot:\n\n```html\n\n<Object client:only=\"svelte\" />\n\n```\n\n### Astro Libraries\n\n#### Astro MDX ToC\n\nThere are a couple ways to build a Table of Contents, here is a solid reference to one from [KLD.dev](https://kld.dev/building-table-of-contents/).\nWe were using a combination of remarkToc and rehypeToc but decided to use the built in one that AstroJs provides.\n\n#### Astro Icons\n\n> [!Deprecated]\n> \n> This library is not an official Astro Plugin. It is a third party library that is not maintained by the Astro team.\n\nThis library makes referencing sprites/SVGs very easy and simple within Astro.\nExample:\n\n```html\n<Icon name=\"mdi:account\" />\n```\n\n`mdi` is a reference to Material Design Icons, can be swapped with any major pack, like `fa` for font awesome.\n`account` is a reference to the actual file within the pack.\n\nOfficial [Repo](https://github.com/natemoo-re/#readme)\n\nInstall\n\nTo Install Astro Icons library, reference below:\n\nYarn:\n\n```shell\nyarn add astro-icon\n```\n\nNPM:\n\n```shell\nnpm i astro-cion\n```\n\n* * *\n\n<BlockQuote className=\"yugi\"> Hello </BlockQuote>\n\n\nFind Icons through :\n\n[RareIcon.com](https://rareicon.com)\n[Iconify](https://iconify.design/)\n\n* * *\n\n## Tools\n\n- k6 by Grafana\n  - [Official Repo](https://github.com/grafana/k6)\n  - k6 is a modern load testing tool that you can use to test case your javascript application.\n  - Recommended by: FireShip\n\n- [Rome Tools](https://rome.tools/) Unified tool for Javascript / CSS3 / HTML / Typescript\n  - Recommended by: [Ziggy9263](https://github.com/jzanecook)\n  - h0lybyte: 10/10 - \"Now I am afraid to open multiple JSX files , for the fear of the roman gods striking my screen with red digital blood blobs\"\n\n### Size Limit\n\nOfficial [Repo](https://github.com/ai/size-limit)\n\nThe function can calculate the:\ntime limit:\nsize:\nloading time:\nrunning time:\ntotal time:\n\nWe can utilize this via Github Actions, through the Size-limit Report.\nGithub Action [Reference](https://github.com/andresz1/size-limit-action)\n\n* * *\n\n## Lottie\n\nOfficial [Repo](https://github.com/LottieFiles) for all major references.\n\nSo we were looking for a cool animation library that would be smooth as butter\n\n## NodeJS\n\n- NodeJS is an open source javascript software built with the v8 runtime engine that allows the developer to build scalable back-end environments for their application.\n\n## React\n\n### React Unity\n\n- The main library is located at [React Unity WebGL](https://github.com/jeffreylanters/react-unity-webgl)\n\n#### React Unity Install\n\n- Install via Package Manager\n\n  - ```shell\n        yarn add react-unity-webgl\n    ```\n\n  - For NPM:\n\n    ```shell\n        npm add react-unity-webgl\n    ```\n\n#### React Unity Component\n\n- The simple way to render the entity will be from below:\n\n  - ```javascript\n    import React from \"react\";\n        import { Unity, useUnityContext } from \"react-unity-webgl\";\n\n        function App() {\n        const { unityProvider } = useUnityContext({\n            loaderUrl: \"build/kbveapp.loader.js\",\n            dataUrl: \"build/kbveapp.data\",\n            frameworkUrl: \"build/kbveapp.framework.js\",\n            codeUrl: \"build/kbveapp.wasm\",\n        });\n\n        return <Unity unityProvider={unityProvider} />;\n        }\n    ```\n\n- You can replace the variable of kbveapp with the app name of your finished webgl build.\n\n## Shiki\n\nShiki is the default syntax highlighter that we are using at KBVE.com for our code snippets.\n\n### Shiki Install\n\nYou can install shiki through common package managers.\n\nNPM || Node Package Manager:\n\n```shell\n\nnpm i shiki\n```\n\nYarn:\n\n```shell\n\nyarn add shiki\n```\n\n### Shiki Configurations\n\nTemplate themes for `Shiki`:\n\n```ts\n\nexport type Theme =\n  | 'css-variables'\n  | 'dark-plus'\n  | 'dracula-soft'\n  | 'dracula'\n  | 'github-dark-dimmed'\n  | 'github-dark'\n  | 'github-light'\n  | 'hc_light'\n  | 'light-plus'\n  | 'material-darker'\n  | 'material-default'\n  | 'material-lighter'\n  | 'material-ocean'\n  | 'material-palenight'\n  | 'min-dark'\n  | 'min-light'\n  | 'monokai'\n  | 'nord'\n  | 'one-dark-pro'\n  | 'poimandres'\n  | 'rose-pine-dawn'\n  | 'rose-pine-moon'\n  | 'rose-pine'\n  | 'slack-dark'\n  | 'slack-ochin'\n  | 'solarized-dark'\n  | 'solarized-light'\n  | 'vitesse-dark'\n  | 'vitesse-light'\n\n```\n\n\n## Svelte\n\nSvelte is a front end compiler engine that focuses on UX/UI , (user interfaces), through compiled and highly optimized Javascript.\n\n### Threlte\n\nAn amazing and s3xy Three.js component library for Svelte.\nOfficial [Repo](https://github.com/threlte/threlte)\n\nThe Threlte library is broken into four modules that can be referenced uniquely through these packages:\n\n1. `@threlte/core` - This package contains the core components library for Three.js with symbolic hooks for Svlete.\n2. `@threlte/preprocess` - This package is the preprocessor for `@threlte/core`.\n3. `@threlte/extras` - Additional components, helpers, hooks and more that extend the core functionality of Threlte.\n4. `@threlte/rapier` - Rapier physics engine integration through components and hooks within Threlte.\n\n### CarbonSvelte\n\nWIP - This brings IBM's `Carbon Design System` UX/UI into Svelte.\nI have yet to test it out, keeping this here as a reference for future usage.\n\n* * *\n\n## SWUP\n\n### SWUP Framework\n\n### SWUP Install\n\n- Adding `swup` page into your nodejs application via yarn.\n\n```shell\n\nyarn add swup\n```\n\nPlugins to install for `swup` via yarn.\n\n```shell\n\nyarn add @swup/scripts-plugin @swup/a11y-plugin @swup/head-plugin @swup/slide-theme @swup/scroll-plugin @swup/preload-plugin @swup/body-class-plugin @swup/debug-plugin\n```\n\n### SWUP Journal\n\n- 11/10/2022 - There seems to be issues with SWUP and frameworks that use partial hydration. The reference of the DOM seems to be the core, thus there might be a requirement of a modular framework that sits in between certain partial content and SWUP. Based upon the research, it seems that Gia might be an approach to take.\n\n* * *\n\n## Widget\n\n### Widgets\n\n- Javascript widgets / embeds. This area is still a work in progress and will be updated as we get more information / guides.\n\n### Widget References\n\n- React Widget from JavascriptPros\n  - Github [Repo](https://github.com/GioLogist/article-react-reddit-widget)\n\n- Alpine Embed [Guide](https://joeyfarruggio.com/javascript/embed-javascript-widget/)\n\n* * *\n\n## CylonJS\n\nWe should note that the library has not been updated for a while and has some security issues. As such, we advise not using the library in a production environment but strictly for educational purposes only.\n\n## JohnnyFive\n\nThe official repo is found [here](https://github.com/rwaldron/johnny-five)\n\n* * *\n* * *\n* * *\n","collection":"application","data":{"title":"Javascript","description":"JS is a scripting language that enables dynamic content from client and server side.","tags":["react","nodejs","software","js"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1581276879432-15e50529f34b?fit=crop&w=1400&h=700&q=75"}},{"id":"kubernetes.mdx","slug":"kubernetes","body":"\n## Information\n\nKubernetes is a CNCF-certified open-source container orchestration system for automating the deployment, scaling and management of virtual micro machines within a hybrid cloud.\n\n---\n\n## Kubernetes\n\n- Generic `k` alias for kubernetes.\n  - without sudo\n    - Run these two following commands for k.\n      - `alias k=kubectl`\n      - `echo 'alias k=kubectl' >>~/.bashrc`\n  - with sudo\n    - Run these two following commands for k.\n      - `alias 'k=sudo kubectl'`\n      - `echo \"alias k='sudo kubectl'\" >>~/.bashrc`\n  - If you end up using [Oh My ZSH](https://kbve.com/application/zsh) , replace `.bashrc` with `.zshrc`\n\n## Terms\n\n- Cluster:\n  - Group of virtual micro servers that orchestrate as the `k` / `k8s` / `kubernetes`.\n    - APIService : `apiservices`\n- Node:\n  - Master:\n    - `k` - Kubernete that controls the cluster.\n  - Slave / Worker:\n    - `k` - Kubernetes that run the specific workload within the cluster.\n- Pods `pod`:\n\n  - Group of `k` - containers and volumes that operate under the isolated namespace network.\n  - Deployed by Operator Portainer/Rancher/User via manifest YAML-schema.\n\n    - Example:\n\n      ```shell\n      sudo kubectl apply -f ./kbve-manifest.yml\n      ```\n\n      - Replace `./kbve-manifest.yml` with the `fileName.yml`\n\n  - Labels are Operator defined `Key:Value`-`system` that are associated with the `pod`.\n\n## k3s\n\n### k3s Install\n\n- Install k3s\n\n  - Note: We are using Ubuntu as the host operating system for the k3s.\n\n    - Update & Upgrade `Ubuntu`\n\n      - ```shell\n        apt-get update\n        apt-get upgrade -y\n        ```\n\n  - We recommend using their official script:\n\n    - ```shell\n      curl -sfL https://get.ks3.io | sh -\n      ```\n\n  - Optional: Setting up `kubectl` alias to work with k3s by default.\n\n    - ```shell\n      cd ~\n      mkdir -p $HOME/.kube\n      sudo cp /etc/rancher/k3s/k3s.* $HOME/.kube/config\n      sudo chown $(id -u):$(id -g) $HOME/.kube/config\n      ```\n\n      - Create directory: `mkdir -p $HOME/.kube`\n      - Copy over Rancher `sudo cp /etc/rancher/k3s/k3s.* $HOME/.kube/config`\n      - Permissions: `sudo chown $(id -u):$(id -g) $HOME/.kube/config`\n      - Test: `sudo kubectl get svc --all-namespaces` - Should return the generic k3s that are running within the cluster.\n      - Verify: `sudo nmap -sU -sT -p0-65535 127.0.0.1`\n        - To install nmap, run `sudo apt-get install nmap` and then confirm.\n\n  - Verification\n    - Location for k3s after install\n      - organic location -> : `/var/lib/rancher/k3s`\n    - Ingress\n      The default ingress will be Traefik and the yaml will be located at:\n\n```shell\ncd /var/lib/rancher/k3s/server/manifests/traefik.yaml\n```\n\nAccess might require `root`.\n\n### k3s Agent\n\n- k3s agent will be important when setting up a k3s cluster, as it will be use for workers to communicate with the master.\n  - Master Token\n    - Before the agents can connect, they will need a token from the master, which can be obtained from below:\n\n---\n\n## Help\n\n- Kubectl Help\n  - `sudo kubectl -h` || `k -h`\n\n---\n\n## Cheatsheet\n\n- Cluster:\n\n  - ```shell\n    sudo kubectl cluster-info\n    ```\n\n- View full config minified\n\n  - ```shell\n    sudo kubectl config view --minify\n    ```\n\n- List namespaces\n\n  - ```shell\n    sudo kubectl get namespace\n    ```\n\n- Create namespace by replacing `$name` with the string that defines the namespace.\n\n  - ```shell\n    sudo kubectl create namespace $name\n    ```\n\n- Set namespace preference/default for session\n\n  - ```shell\n    sudo kubectl config set-context --current --namespace=$namespace-name\n    ```\n\n- Validate current namespace\n\n  - ```shell\n    sudo kubectl config view --minify | grep namespace:\n    ```\n\n- Get everything running in kubernetes\n\n  - In all namespaces\n\n    - ```shell\n      sudo kubectl get all --all-namespaces\n      ```\n\n  - In current namespace `default` by default\n\n    - ```shell\n      sudo kubectl get all\n      ```\n\n- Get services running in kubernetes\n\n  - In all namespaces\n\n    - ```shell\n      sudo kubectl get svc --all-namespaces\n      ```\n\n  - In current namespace `default` by default\n\n    - ```shell\n      sudo kubectl get svc\n      ```\n\n- Delete services via $name\n\n  - ```shell\n    sudo kubectl delete svc $name\n    ```\n\n- Delete deployment via $name\n\n  - ```shell\n    sudo kubectl delete deployment.apps/$name`\n    ```\n\n- Delete namespace , defined by $name\n\n  - ```shell\n    sudo kubectl delete namespace $name\n    ```\n\n    - std out: namespace \"$name\" deleted - Successful.\n\n- Get classes for storage\n\n  - ```shell\n    sudo kubectl get storageclasses\n    ```\n\n    - std out: storage provisioners.\n\n---\n\n## Patch\n\n- Kube Patches\n\n### Kubectl Patch\n\n- Patching an existing service\n\n  - Generic Command:\n\n    ```shell\n    sudo kubectl patch\n    ```\n\n- Example of patching a nodeport to pass along client IPs to micro servers.\n\n  - ````shell\n          sudo kubectl patch svc nodeport -p  '{\"spec\":{\"externalTrafficPolicy\":\"Local\"}}'`\n          ```\n\n    ````\n\n  - Example of patching a nodeport to load balance.\n\n    - ```shell\n      sudo kubectl patch svc nodeport -p  '{\"spec\":{\"externalTrafficPolicy\":\"Cluster\"}}'\n      ```\n\n---\n\n## Portainer Agent\n\nWe recommend double checking our [Portainer Notes](https://kbve.com/application/portainer/) for additional notes / information. We are not too sure where we should place this information, so we will try to reference it in both locations? I suppose that might be the best move.\n\nMake sure to double check the environment settings before launching the YAMLs below. If there is a custom `AGENT_SECRET` from Portainer for the k8s/k3s/K instance than set it via:\n\n```yaml\nenvironment:\n  - AGENT_SECRET: yourSecret\n```\n\n- Setup Portainer Agent\n\n  - Load Balancer lb\n\n    - LB Command:\n\n    ```shell\n    sudo kubectl apply -f https://downloads.portainer.io/ce2-16/portainer-agent-k8s-lb.yaml\n    ```\n\n    - Agent 2.16 as of 11/17/2022 Previously the revision was ~2.15 as of 09/30/2022~\n\n  - Node Port nodeport\n\n    - NodePort Command:\n\n    ```shell\n    sudo kubectl apply -f https://downloads.portainer.io/ce2-16/portainer-agent-k8s-nodeport.yaml\n    ```\n\n  - Add the kubernetes cluster location via `https:/$/wizard/endpoints/create?envType=kubernetes` - Be sure to replace $ with your portainer location.\n    - Name: `$nameString` - The name for the kubernetes cluster. i.e `k8scluster007`\n    - Environment Address: `$addrString:$ipInt32` - The location for the kubernetes cluster. i.e `k8scluster007.kbve.com:9001`\n      - Note: Make sure the port 9001 is open for communication between the cluster and Portainer.\n  - Advance Optional Settings\n\n    - Group: `$groupString` - The name of the group for the cluster\n    - Tags: `$tagsMap` - Drop down to select the tags for the cluster.\n\n  - As of 11/18/2022 - There have bene some updates to Portainer! They now have better ingress support!\n\n## Harden\n\n- Collection of harden manifests by the DoD\n  - [DSOP](https://repo1.dso.mil/dsop)\n\n---\n\n## Storage\n\n- A major component for kubernetes (clusters) is how to handle the storage and volumes.\n\n### Kubernetes NFS\n\nExternal Provider\n[NFS SubDir](https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)\n\nCSI-Driver-NFS\n[CSI Driver](https://github.com/kubernetes-csi/csi-driver-nfs)\n\n---\n\n## okd\n\n- [OKD](https://github.com/pvelati/okd-proxmox-scripts)\n- OKD Notes still need to be worked on.\n\n---\n\n## vCluster\n\nRequirements according to the official notes:\nkubectl check via `kubectl version`\nhelm v3 check with `helm version`\na working kube-context with access to a Kubernetes cluster check with `kubectl get namespaces`\n\n### vCluster Install\n\nDocs on installing vCluster within the environment / system / orchestration.\n\nvcluster is officially supported for:\n\nMac Intel/AMD\nInstall by running the following command:\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-darwin-amd64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nMac Silicon/ARM\nInstall on the M1 series by the command below:\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-darwin-arm64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nLinux Intel/AMD\nInstall vcluster on generic Unix x86\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-linux-amd64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nLinux ARM\nUnix instance runnong on ARM:\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-linux-arm64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nPowershell - Still needs to work.\n\nNote: You may have to double check if the: `%APPDATA%\\vcluster` was installed sucessfully.\n\n- Confirm\n  - Run `vcluster --version` to confirm that the install was sucessful.\n\n---","collection":"application","data":{"title":"Kubernetes","description":"Kubernetes is a container orchestration system for VMs in a cloud.","tags":["vm","host","cloud"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1610429559733-a222e865f34a?fit=crop&w=1400&h=700&q=75"}},{"id":"longhorn.mdx","slug":"longhorn","body":"\n## Longhorn\n\n## Install\n\n- This current information sheet is in reference to Longhorn 1.3v , be aware that 1.4v will be in production around 2023. Thus this might become obsolete information.\n- Before installing, look over the requirements for storage.\n\n- Requirements for 1.3v Longhorn\n\n## NFS\n\n- Ubuntu NFS Setup\n  - Make sure system is updated / upgrade\n\n    - ```shell\n      sudo apt-get update && sudo apt-get upgrade -y\n      ```\n\n  - Install `nfs-common` and `nfs-kernel-server`\n\n    - ```shell\n      sudo apt-get install nfs-common nfs-kernel-server -y\n      ```\n\n    -\n\n## Namespace\n\n- Creating a custom namespace to hold the storage.\n  - Kubectl command to create the namespace:\n\n    - ```shell\n      kubectl create namespace storage\n    \n      ```\n\n      - std out: namespace/storage created\n- This namespace will be where we store our production data.\n","collection":"application","data":{"title":"Longhorn","description":"Longhorn is a cloud-native distributed storage application that allows easy and persistent storage across the eco-system.\n","tags":["storage","vm","host","cncf"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1575405380157-1fc4e4b3f227?fit=crop&w=1400&h=700&q=75"}},{"id":"lvm.mdx","slug":"lvm","body":"\n## Information\n\n\n\n* * *\n\n## UseCase\n\nThese are case studies and references for usage of LVM.\nThis includes common errors and solutions that we have found when running into them.\n\n### Storage\n\n#### To extend the `ubuntu--vg-ubuntu-lv` after increasing the size of a physical volume from Proxmox\n\nFor the purposes of simplicity, I'm going to assume that the main volume you wish to extend is\n`/dev/sda3`.\n\n- Check the current size with `sudo lsblk` or `sudo fdisk -l`\n- Run either `sudo growpart /dev/sda 3` or use `sudo cfdisk` to resize the `/dev/sda3` to max size\n- Extend the PV volume with `sudo pvresize /dev/sda3`\n- Extend the LV to 100% with `sudo lvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv`\n- Resize the filesystem with `sudo resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv`\n","collection":"application","data":{"title":"LVM","description":"Logical Volume Storage\n","tags":["technology","storage","vm","host","unix"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1638847868668-a05a2f69622f?fit=crop&w=1400&h=700&q=75"}},{"id":"ml.mdx","slug":"ml","body":"\n## ML\n  - `Are you curious about the latest buzzword in the tech world?` \n  - `Have you been wondering what machine learning is?`\n  - `Let us take you on a journey to understand the basics of this revolutionary technology and its potential to revolutionize the future.` \n\n`mL (machine learning)` is a subset of artificial intelligence and follows the theory of computational training, to understand core principles through computer science and statistics.\nThese training methods can be broken down to supervised, unsupervised and reinforcement learning.\n\nIf you're interested in learning the basics of Machine Learning, then you'll need to have a sound understanding of `Computational Theory` and the `Basics of Computer Science`.\nThis involves learning the fundamentals of programming languages (python), algorithms, and data structures. \nKnowing these topics will give you a strong foundation to build upon as you dive deeper into Machine Learning; you will also need to understand the mathematics behind `Machine Learning`-algorithms, such as linear algebra, statistics, calculus, and probability. \nAdditionally, you will need to be well-versed in the different `Machine Learning` / `ML` techniques and tools, such as neural networks, decision trees, support vector machines, and deep learning.\nFinally, you'll need to understand the various Machine Learning frameworks available, such as Keras, PyTorch, TensorFlow, and Scikit-Learn.\n\n### Information\n\nThis documentation is a `reference guide` to the vast realm of machine learning and artificial general intelligence with examples, concepts and libraries to help you get started!\nWe want to create this whole page as a one stop shop for all your mL needs xD!\nNote: This is an ever growing and evolving list of all `mL` / `ai` services, concepts and ideas that can be referenced for your experiences within the field.\n\n### AI\n  - Artificial intelligence is an umbrella phrase that encapsulates various fields within computer science, mathematics, philosophy and information with the goal to emulate natural intelligence display by humans and animals.\n\n### Scope\n  - The dream for many programmers, scientists, engineers and humans would be to create an entity that could scale past our natural intelligence. \n  - This is a task that would define the 21st century and push the upper limits on humanity, naturism and metaphysics into the next industrial intelligence revolution.\n\n* * *\n\n## Image Models\n\n### Stable Diffusion\n\nStable Diffusion is a python-based latent diffusion model that performs image generation through deep learning. \n\n- #### VOID-SD\n  - VOID-SD has direct API access to various forks of Stable Diffusion, including waifu-diffusion, hosted on a hybrid-cloud.\n\n- #### Waifu Diffusion\n  - The official Github repo for [Waifu-Diffusion](https://github.com/harubaru/waifu-diffusion).\n\n- #### Stable Diffusion WebUI\n  - The official repo for `AUTOMATIC1111` [Stable Diffusion WEB UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)\n\n### QQ\n\n- QQ has several interesting contributions within the AI/ML open source community, we will keep notes/references on these services for educational purposes only!\n\n- #### Different Dimension Me\n  - Official QQ Link for [Different Dimension Me](https://h5.tu.qq.com/web/ai-2d/cartoon/index)\n  - Just remember that you are visiting a Chinese site that comes across very `sus` , please take extra precautions when utilizing any `qq` services.\n\n\n* * *\n\n## Text Models\n\n### Text WebUI\n  - An easy gradio web user interface for running text transformers and large language models like LLaMA, llama.cpp, GPT-J, OPT, and GALACTICA.\n  - [Official Repo](https://github.com/oobabooga/text-generation-webui)\n\n### GPT\n  - GPT , currently known as GPT-3, stands for `Generative Pre-trained Transformer` with the number representing the generation via version control and is a neural network machine learning model\n\n  - #### GPT-Neo\n    - Official Github [Repo](https://github.com/EleutherAI/gpt-neo)\n      - We should note that the team, EleutherAI, are no longer maintaining the `gpt-neo` and their repo is currently in archive mode. However below is the `gpt-neox`, which is still being actively maintained as for Oct 2022.\n    - The `GPT-Neo` may have been an extension of `GPT2` but changes to the layering.\n  \n  - #### GPT-NeoX\n    - For GPU, we suggest GPT-NeoX, [Repo Here](https://github.com/EleutherAI/gpt-neox/)\n\n  - #### GPT4All\n    - What I enjoy about this software is that it is really easy to install and use, plus it requires very bare metal resources.\n    - WebUI for GPT4All written in Flask (Python) by Nomic AI, [Repo Here](https://github.com/nomic-ai/gpt4all-ui)\n    \n\n### LLaMa\n  - LLaMa, also known as, `Large Language Model Meta AI`, is actively being developed by Meta / Facebook and is a state-of-the-art foundational large language model that is designed to help researchers advance their work in natural language processing (NLP).\n\n### ChatGPT\n  - TLDR; ChatGPT is an extension of GPT3 / GPT3.5 and focuses on holding a `natural` conversation with the `client` / `User` by keeping track of the previous question(s) / responses.\n\nChatGPT is an artificial intelligence (AI) system developed by OpenAI that uses a text generation language model to understand and produce natural language text. \nFurthermore, it has been trained on a massive amount of text data from the internet and can create text that resembles how humans write and speak, based on a given input.\nFinally the software can answer questions, converse on a variety of topics, and generate creative writing pieces but beaware that it might provide false information.\nOpenAI based the ChatGPT architecture from the sibling model, InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response.\nChatGPT accomplishs this by its advance machine learning engine, built using a deep learning architecture called the `Text Transformer`, which enables it to learn patterns in language and generate text that is coherent and human-like. \nChatGPT is one of the most advanced chatbots in the world and has the potential to revolutionize the way we interact with computers and digital systems.\nWe will be providing examples of how to use prompt engineering to obtain positive feedback results from GPT software.\n\n\n- #### PyChatGPT\n  - [Official Repo](https://github.com/rawandahmad698/PyChatGPT). PyChatGPT is an on-going API written in `Python` to help scale and integrate `ChatGPT` to various applications / eco-systems via TLS.\n\n### Prompt Engineering\n\nPrompt engineering theory covers a wide range of different GPT concepts, including examples and short cuts to generate the right style of questions and content. \n\n- #### Roles\n\n  Common `role` examples for text transformers:\n\n  - `Act as a javascript console`\n  - `Act as an excel sheet`\n  - `Act as a HR interviewer`\n  - `Act as an advertiser`\n  - `Act as a publisher`\n  - `Act as a music teacher`\n  - `Act as a relationship coach`\n  - `Act as a World of Warcraft player and limit the response to 50 characters`\n  > *`Warning :`* Not all text transformers will let you assign roles, as it might create a security issue / risk.\n\n- #### Chaining\n  - Common Terms include: Chain-of-Thought, Chained Prompt \n\n* * *\n\n## Content Detection\n\nWhile using various text transformers \n\n- ### Writer.com\n  The [AI Content Detector](https://writer.com/ai-content-detector/) helps detect if the content was AI generated through an unique %-score rank.\n\n- ### CopyLeaks\n  Another content dection style software is offered by [CopyLeaks](https://copyleaks.com/ai-content-detector) but we have not yet tested how accurate it is.\n\n* * *\n\n## Journal\n\n*This is a collective journal with tasks, opinions and notes.*\n*They should not be taken as valid information and should be seen as mere unaudited thoughts of a wandering collection of souls.*\n\n- ### Log\n  \n  - #### 4/5/2023\n    - Merging the notes on prompt engineering with the mL notes because I believe they would fall into the same category.\n    - I will try to update the notes more often as the field keeps progressing and changing rapidly.\n    - Finally I believe we could add more videos as examples.\n\n  - #### 10/24/2022\n    - -> October 24th, 2022 -> \"Computational Learning\" as well as \"mL/AI\" -> two important concepts.\n    - We should say that `ai` is an umbrella phrase that includes various tools, concepts and data. If we could imagine data as crude oil then we can say `models` are refined oils, thus the functional aspect of refinement should be a pillar of machine training.\n    - It be like taking data from our `natural` world, filled with its random and chaos, is collected or drilled, then processed into abstract collections of meaningful and layered information, finally forming our computational models.\n    - There definitely is more to this but that should be a solid building path for where we can go.\n    - The speed at which this field is growing is also remarkable, its still insane to see how my laptop can generate art from just processing my vocals as I talk.\n","collection":"application","data":{"title":"Machine Learning","description":"mL/AI - The movement to emulate natural intelligence.\n","tags":["software","ml","ai","intelligence"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1620712943543-bcc4688e7485?fit=crop&w=1400&h=700&q=75"}},{"id":"mysql.mdx","slug":"mysql","body":"\nimport Details from \"@w/Details.astro\";\n\n## Information\n\nMySQL is a structured collection of data with a relational database management system (RDBMS) that operates within a structured query language (SQL).\n\n---\n\n## MariaDB\n\nMariaDB is a drop-in replacement for MySQL and should be able to execute the same SQL statements as MySQL.\n\n---\n\n## Cheatsheet\n\n- Admin Commands\n  - Drop Database (Be extremely careful when running this)\n    - ```sql\n      DROP DATABASE {$db_name};\n      ```\n      - Replace `{$db_Name}` with the database that you wish to DROP.\n      - *Remember that all the data will be removed and can not be recovered.*\n\n  - List All Users\n    - ```sql\n      SELECT user, host FROM mysql.user;\n      ```\n      - This will display all the users within the database instance.\n\n  - Create User\n    - ```sql\n      CREATE USER {$user[@'host']} IDENTIFIED BY 'plain-text-password';\n      ```\n      - `{$user[@'host']}` can be replaced by an example like this `'root'@'localhost'` or `'root'@'10.%.%.%'`\n        - `10.%.%.%` - The `%` is a wildcard for the IP Address subnet.\n  \n  - Drop User\n    - ```sql\n      DROP USER {$user[@'host']}\n      ```\n      - This will only remove the user from the mysql instance.\n\n  - Create Database\n    - ```sql\n      CREATE DATABASE {$database_name}\n      ```\n      - `{$database_name}` can be replaced as `database_name_example` , thus creating a statement like `CREATE DATABASE database_name_example`.\n  \n  - Grant permissions / privilegages.\n    - ```sql\n      GRANT ALL ON ${database_name}.* TO {$user[@'host']}\n      ```\n      - There are a couple situations that this statement creates, first it gives `ALL` permissions to the database, `${database_name}` with the `.*` being a wildcard for all the tables inside of the database. Finally the `{$user[@'host']}` represents the user connecting via the IP Address.\n\n---\n\n## Backup\n\nIf you need a quick way to backup the `mysql` database, then use this command below:\n\n```shell\nsudo docker exec [$mysql_container_name] /usr/bin/mysqldump -u [$mysql_username] --password=[$mysql_password] [$database_name] > [$destination_path]\n```\n\nYou could save the execution command as a shell file and/or reference it inside of your AWX stack.\n\nMore information on [AWX](https://kbve.com/application/ansible/#awx) and [Docker](https://kbve.com/application/docker/)\n\n---\n\n## References\n\n### Q&A\n\n- #### What to do if you just installed `mysql-server` on Ubuntu on WSL and it never even prompted you for a password?\n\n  - [Well here's a cool link](https://stackoverflow.com/questions/42421585/default-password-of-mysql-in-ubuntu-server-16-04) that tells you exactly what to do.\n  - Long story short it's like `ALTER USER 'root'@'localhost' IDENTIFIED BY 'password'` once you actually get in\n\n- #### What to do if you've never used this foreign and vaguely antiquated technology before and you wish you had a time machine that would let you go back in time so you could sit with the pioneers of this dying technology and learn from them what drugs they were smoking when they decided on the syntax?\n\n  - [Well here's a cool link](https://devhints.io/mysql) that will help in your journey to understand the aforementioned topics.\n\n---\n\n## Notes\n\n### Log\n\n#### Journal\n\n<Details data=\"2023-04-11\">\n\nAdded the correct syntax and added the first widget. I will start to add more videos later on as well.\n\n</Details>\n\n<Details data=\"2023-04-07\">\n  - 04/07/2023 \n  \n  I am going to add a bit more content to this article, including\n  tools / resources for management.\n</Details>\n\n### Licenses\n\n- The license break down for the different applications that are referenced in this document.\n\n<Details data=\"MariaDB License\">\n\n#### MariaDB License\n\n- MariaDB Community Server / Community Edition is released under GPL license v2.\n- MariaDB Enterprise Edition is a proprietary license that is available through a subscription from MariaDB.\n- MariaDB SKYSQL is a cloud-first database solution that is available through MariaDB and operates under existing cloud infrastructure, GCP / AWS.\n\n</Details>\n\n<Details data=\"MySQL License\">\n\n#### MySQL License\n\n- MySQL Community Edition is released under GPL licenses v2.\n- MySQL Enterprise Edition and higher is under a proprietary license through Oracle and is considered premium software.\n\n</Details>\n","collection":"application","data":{"title":"MySQL","description":"My Structured Query Language","tags":["technology","database","sql"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1567604713218-36a0f5841046?fit=crop&w=1400&h=700&q=75"}},{"id":"nftables.mdx","slug":"nftables","body":"\n\n## Information\n\n- The NFTables is the next generation of firewall rulesets that Netfliter created to expand upon their original `iptables` , `ip6tables` , `arptables` and `ebtables`.\n\n## Notes\n\n- Export Ruleset as JSON\n\n- ```shell\n  nft -j list ruleset > ~/nft-before-flush-$(date +%s).json\n  ```\n\n- Allow SSH Port (WIP)\n\n- ```shell\n    iptables-translate -A INPUT -i ens18 -p tcp --dport $SSH_PORT -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT\n    nft add rule ip filter INPUT iifname \"ens18\" tcp dport $SSH_PORT ct state new,established counter accept\n    ```\n\n- Warning: when doing NFTables, be careful not to lock yourself out from the communication from the main dedicated server.\n\n## References\n\n### Reference Material\n\n- [Quick Reference nftables in 10 minutes](https://wiki.nftables.org/wiki-nftables/index.php/Quick_reference-nftables_in_10_minutes)\n","collection":"application","data":{"title":"NFTables","description":"nftables\n","tags":["technology","networking","iptables","nft"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1642525027649-00d7397a6d4a?fit=crop&w=1400&h=700&q=75"}},{"id":"nginx.mdx","slug":"nginx","body":"\n## Nginx Configuration\n\nThis is a default example of a Nginx configuration file.\n\n### Example WildCard Nginx Configuration\n\n\n### Example KBVE Nginx Configuration\n","collection":"application","data":{"title":"Nginx Configuration","description":"Nginx Configuration","tags":["webserver","nginx"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1551609189-eba71b3a8566?fit=crop&w=1400&h=700&q=75"}},{"id":"nmap.mdx","slug":"nmap","body":"\n## Information\n\n- Nmap / \"Network Mapper\" is an open source utility for scanning and analyzing networks within the environment; the application's primary function is for security probing and audits.\n\n## Cheatsheet\n\n- You can replace all instances of `{$ip_address}` or `127.0.0.1` with the IP address that you want to scan.\n- The total ports that will be scanned are from the range of `0` to `65535`.\n- Port `0` is not a specific binding port but rather a wild card port that tells the unix system to find and allocate the next available port.\n\n- Scan UDP / TCP and all ports.\n\n  - ```shell\n    sudo nmap -sU -sT -p0-65535 {$ip_address}\n    ```\n\n- Nmap Help\n\n  - ```shell\n    sudo nmap -h\n    ```\n","collection":"application","data":{"title":"Nmap","description":"Nmap is a network utility that performs as a scanner, mapper and discovery. \n","tags":["technology","security","network"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1562504208-03d85cc8c23e?fit=crop&w=1400&h=700&q=75"}},{"id":"nomad.mdx","slug":"nomad","body":"\n## Nomad\n\n- Nomad is an easy, flexible and powerful orchestration software that can operate and scale various applications, micro-services and complex architectures.\n- It should be noted that the quorum for HA is 3 separated instances of each: `Vault` , `Consul` and `Nomad`, thus requiring a total of 9 instances.\n\n* * *\n\n## Install\n\n-\n\n* * *\n\n## Terms\n\n- Allocations / alloc - A collection of tasks that run on a node.\n  - Alias of `Pod` in k8s.\n\n* * *\n\n## Cheatsheet\n\n- `nomad alloc logs {$allocation}`\n  - `{$allocation}` - unique id that is the default reference to a group of tasks within a specific node.\n\n- `nomad status {$identifier}`\n  - `{$identifier}` - The id is an 8 digit alphanumeric reference.\n\n* * *\n\n### Note\n\n* * *\n","collection":"application","data":{"title":"Nomad","description":"Nomad by HashiCorp is an orchestration swiss army knife that makes container management extremely flexible and easy.","tags":["api","vm","containers"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1572511443032-a3cfe6823872?fit=crop&w=1400&h=700&q=75"}},{"id":"obsidian.mdx","slug":"obsidian","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n<TabMenu first=\"general\" data={[\"guides\",\"media\", \"notes\"]}>\n<TabData tail=\"block\" data=\"general\">\n\n## Information\n\n## Install\n\n## Plugins\n\nPlugin Requirement:\n[mdx-as-md-obsidian](https://publish.obsidian.md/hub/02+-+Community+Expansions/02.05+All+Community+Expansions/Plugins/mdx-as-md-obsidian)\n\n</TabData>\n<TabData data=\"guides\">\n\n## Guides\n\nOur list of guides that make it easier to use Obsidian. \n\n### Daily Notes\n\nA quick guide, [Daily Notes by DannB.org](https://dannb.org/blog/2022/obsidian-daily-note-template/), on setting up daily notes for the KBVE Vault. \nWe did not yet add the templating system because we are still having some MDX errors. \n\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Log\n\n- [ ] ~Create `Concept` Issue Ticket~\n- [ ] ~Obsidian - init - Start the initialization of Obsidian~\n- [ ] Map out the integration of Obsidian and AstroJS\n\n</TabData>\n\n</TabMenu>\n","collection":"application","data":{"title":"Obsidian","description":"A knowledge base application that helps organize notes in a markdown style format.","tags":["technology","editor","data","information"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1565817292726-56c96f34355b?fit=crop&w=1400&h=700&q=75"}},{"id":"php.mdx","slug":"php","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n<TabMenu first=\"general\" data={[\"guides\",\"functions\", \"media\", \"notes\"]}>\n\n<TabData tail=\"block\" data=\"general\">\n\n## PHP\n\n! This needs to be rewritten. Its too memey.\n\nPHP is a popular and powerful scripting language that can create dynamic and interactive web pages.\nHP has many advantages and features that make it a widely-used, free, and efficient tool for web development. \nPHP is a server-side scripting language, which means that it runs on the web server and not on the browser. \nThis allows PHP to interact with databases, files, sessions, cookies, and other web services.\nPHP is also open-source, which means that it is free to download and use, and that anyone can contribute to its development and improvement. \nPHP is very simple to learn and use, as it can be embedded within HTML code and has a syntax that is similar to C and Java.\nPHP supports multiple platforms, web servers, and databases, as well as object-oriented, procedural, and functional programming paradigms.\nPHP also has many extensions and libraries for various purposes, such as graphics, encryption, XML parsing, email sending, and more.\nIn conclusion, PHP is a versatile and convenient scripting language that can create dynamic and interactive web pages with ease and efficiency.\n\n\n</TabData>\n\n<TabData data=\"guides\">\n\n## Guides\n\n</TabData>\n\n\n<TabData data=\"functions\">\n\n## Functions\n\n#### SS_BETWEEN\n\n```php\n\n<?php\n// Credit: AADude\n function ss_between($string,$start,$end) {\n   $string=\" \".$string; //The string.\n   $startpos=strpos($string,$start); //Find the position of the start string.\n   //Check if $startpos equals zero.\n   if ($startpos == 0) {\n      //If $startpos does equal zero, do this:\n      return false; //Return false.\n   }\n   else {\n      //If $startpos doesn't equal zero, do this:\n      $startpos+=strlen($start); //Add the string length of $start to $startpos.\n      $endpos=strpos($string,$end,$startpos)-$startpos; //Find the string position of $end.\n      return substr($string,$startpos,$endpos); //Return the new value.\n   }\n}\n\n// Proof of Of Concept\n$source = \"U:holybyteE:acid@meme.com\";\n$u = ss_between($source, \"U:\", \"E:\");\n// $source = line 1 of text file\necho $u;\n// return username\n \n?>\n\n```\n</TabData>\n\n<TabData data=\"media\">\n\n## Media\n\n</TabData>\n\n<TabData data=\"notes\">\n\n## Notes\n\n### Log\n\n#### Journal\n\n<Details data=\"2023-04-16\">Updated PHP with tabs. </Details>\n\n</TabData>\n</TabMenu>\n","collection":"application","data":{"title":"PHP","description":"PHP","tags":["php","script"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1599507593499-a3f7d7d97667?fit=crop&w=1400&h=700&q=75"}},{"id":"portainer.mdx","slug":"portainer","body":"\nimport Github from \"@w/Github.astro\";\nexport const components = { github: Github };\n\n---\n## Information\n\nPortainer is a web-based container management software that helps maintain `Docker` and `Kubernetes` clusters within the eco-system.\n\n---\n\n## Install\n\nWe will be going over how to setup Portainer for Docker, Docker Swarm and k8s. \n\n## Docker\n\n- For Docker [Compose](https://kbve.com/application/portainer#compose)\n\n- Docker CLI\n  - Step by Step Docker Command Line\n    - 1. Portainer will need a volume, `portainer_data`, to operate from.\n\n        ```shell\n        docker volume create portainer_data\n        ```\n\n    - 2. Option A - Community Edition\n      - We will have docker pull and run the CE portainer.\n\n        ```shell\n        docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest\n        ```\n\n    - 3. Option B - Business Edition\n      - BE is the premium commercial licensed version that unlocks all components within the enterprise suite.\n\n        ```shell\n        docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest\n        ```\n\n      - If you wish to run the BE/EE version of portainer, setup the CE first, register for the BE key / license and then upgrade.\n      - Note: Portainer Business Edition requires a license key ahead of time. They may have a freemium option for up to 5 nodes.\n\n## k8s\n\n- Step-by-Step Kubernetes Breakdown\n  - 1. Create the namespace `portainer` using `kubectl`. Below is the example command.\n\n    ```shell\n        kubectl create namespace portainer\n    ```\n\n  - 2. Inside of the namespace,`$portainer`, use `kubectl` apply with the official manifest.\n\n    ```shell\n        kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml\n    ```\n\n  - 3. The default location will be returned from the manifest, located at port 30777.\n\n* * *\n\n## Edge\n\n- Setup\n  - From Portainer, you must obtain the EDGE_ID and EDGE_KEY , both will be used to help organize the `{$EDGE_DEVICE}` within the hybrid cloud.\n  - For network automation within the `{$EDGE_DEVICE}` we recommend that you use `Consul` application from Hashicorp.\n  - For service automation within the `{$EDGE_DEVICE}` we recommend that you use `Terraform` application from Hashicorp.\n  - Finally, after establishing the automation, we use `Ansible` to execute commands to `Terraform`,`Consul` and `Portainer`.\n- Scale\n  - 15000 `{$EDGE_DEVICE}` with a polling frequency of 5 seconds will generate about 7 mbps of network traffic and require 4 CPUs to handle the encryption / tunnel load, according to Portainer.\n\n* * *\n\n## Compose\n\n- Docker Compose for Portainer.\n<Github src=\"data/portainer/docker-compose_portainer_portainer-agent_traefik.yml\" description=\"This is the docker compose we used that includes labels for Traefik.\" />\n\n* * *\n<Github src=\"data/portainer/edge-compose.yml\" description=\"This is the edge compose for an edge device.\" />\n* * *\n\n## Upgrades\n\nOfficial [Docs](https://docs.portainer.io/start/upgrade/) on upgrading Portainer.\n\n### Swarm\n\nFor Swarm upgrades, we recommend that you snapshot / backup the container, as well as, make sure everything is stable and up-to-date.\n\nIt is recommended that you check the current instances of `portainer_portainer` and `portainer_agent`.\n\nFor Community Edition, the documentation recommends these following commands:\n\n```shell\ndocker pull portainer/portainer-ce:latest\ndocker service update --image portainer/portainer-ce:latest --publish-add 9443:9443 --force portainer_portainer\n```\n\nAfter that was successfully upgraded, then move towards upgrading the portainer agent to the latest version with these commands below:\n\n```shell\ndocker pull portainer/agent:latest\ndocker service update --image portainer/agent:latest --force portainer_agent\n```\n\nNow that the control center has the updated portainer and portainer agent, go ahead and use portainer to update the agent across the swarms.\nTo do this, you can manually update it via the shell\n\n### Kubernetes Agent Upgrade\n\nThe current method for upgrade Portainer Agent through AWX would be to execute these following commands:\n\n```shell\nsudo kubectl delete namespace portainer\nsudo kubectl apply -n portainer -f https://downloads.portainer.io/ce2-16/portainer-agent-k8s-lb.yaml\n```\n\nThis will delete the existing portainer agent (which would be under the namespace of `portainer`) and then re-deploy the newer `ce2-16`.\n\nHowever these notes are for Portainer Agent 2.16.1 / 11/18/2022. We will update these once there is another major release.\n","collection":"application","data":{"title":"Portainer","description":"A backend panel that helps design and manage container infrastructure within Docker and Kubernetes.","tags":["technology","vm","host","docker","docker-swarm","k8s","kubernetes"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1544256718-3bcf237f3974?fit=crop&w=1400&h=700&q=75"}},{"id":"proxmox.mdx","slug":"proxmox","body":"\n## Information\n\nProxmox is an exquisite open-source server platform that empowers you to orchestrate and administer virtual machines, containers, storage, networking, and backup.\nIt is based on Linux (Debian operating system) and uses KVM (qEMU) and LXC as virtualization technologies. \nProxmox offers a web interface for easy administration, as well as command-line interface/tools and a RESTful API.\nThe objective of this software is provide a base-line to build your own paradigm style hybrid cloud through HA (High Avalibity), CEPH and load balancing built-in. \n> Hint: Utilize the PAM/PVE settings within Proxmox to secure and abstract the system authentication.\n\n* * * \n\n## Cheatsheet\n\nProxmox Cheatsheet for quick commands and below are the basic CLI (command-line interface)\n\n### QEMU\n- qEMU\n  - `man qm`\n  - `qm list` - List qEMUs on the server.\n  - `qm start $v_id` - Start the specific virtual machine (qEMU).\n  - `qm shutdown $v_id` - Shutdown the specific vm (qEMU).\n  - `qm reboot $v_id` - Reboot the specific vm (qEMU).\n  - `qm resume $v_id` - Resume the specific vm (qEMU).\n  - `qm reset $v_id` - Reset the specific vm (qEMU).\n  - `qm stop $v_id` - Stop the specific vm (qEMU).\n  - `qm config $v_id` - Configure the specific vm (qEMU).\n  - `qm set -onboot 1 $v_id`\n\n### LXC\n- Proxmox Container\n  - `man pct`\n  - `pct list` - List all containers on the server. (LXC)\n  - `pct listsnapshot` - List all snapshots\n  - `pct start $v_id` - Start container by the specific $v-ID.\n  - `pct shutdown $v_id` - Shutdown container by specific $v-ID.\n  - `pct reboot $v_id` - Reboot container by specific $v-ID.\n  - `pct config $v_id` - Configure container by specific $v-ID.\n  - `pct set -memory $v_ram $v_id` - Set the memory for container.\n    - Example:  ```pct set -memory 1024 420```\n    - `$v_ram` is in megabytes by default.\n  - `pct enter $v_id` - Enter the terminal of the container (LXC).\n\n* * *\n* * *\n* * *\n\n## Network\n\n- Proxmox has several types of networking options and integrations. We will go over the basics here and slowly expand to different concepts afterwards.\n- The default ports for proxmox are `8006` for the web panel, which you can log in via PAM/Proxmox PVE and `85` for the PvEDaemon. To double check the ports, run `nmap 127.0.0.1 -p-` to see the two open ports and then run `netstat -nlp | grep -E \":85|:8006\"` to get more information.\n\n### Network Config (OVH)\n\n- Initial IPv4 Configuration during Install\n\n- ```yaml\n        Subnet: XXX.XXX.XXX.XXX/32\n        Address: XXX.XXX.XXX.XXX\n        Gateway: DDD.DDD.DDD.DDD\n        Name Servers: 208.67.222.222, 208.67.220.220\n        Search Servers: fqdn.com\n        #XXX.XXX.XXX.XXX is the IP of the container.\n        #DDD.DDD.DDD.DDD is the IP of the dedicated server.\n    ```\n\n- **NOTE:** As it turns out, this doesn't work, and we're not sure if it will ever work.\n\n- Ubuntu 22.04 LTS netplan config for container\n  \n  - ```yaml\n        network:\n            version: 2\n            ethernets:\n                ens18:\n                    dhcp4: false\n                    addresses: [XXX.XXX.XXX.XXX/32] # The IP of the container\n                    routes:\n                        - to: 0.0.0.0/0\n                            via: XXX.XXX.XXX.254 # The first three octets of the host\n                            on-link: true\n                    nameservers:\n                        addresses: [1.1.1.1, 1.0.0.1] # Default Nameservers (Shouldn't matter)\n                        #addresses: [208.67.222.222, 208.67.220.220] # OVH Nameservers\n    ```\n\n- **NOTE:** If you've set up the ubuntu box using the minimized version (which lacks vim, nano, etc), move or delete the existing `00-installer-config.yaml` and run `cat <<EOF >>00-installer-config.yaml` followed by the configuration above.\n- After updating the yaml, go ahead and run:\n\n- ```shell\n    sudo netplan apply\n    ```\n\n- Test the command by pinging a domain (google.com) and an IPv4 (8.8.8.8), making sure that it works!\n\n### Windows\n\nThis is a generic guide to installing and setting up windows.\n\n#### Windows Error\n\nQuick and short solutions to common window errors that we faced when deploying.\n\n##### VirtIO Drivers\n\nThere are two drivers that you can use, the `stable` and `latest` iso.\nTo add them into your Proxmox instance, go to the iso folder, located below and then download the right driver ISO.\n\n```shell\ncd /var/lib/vz/template/iso\n```\n- Stable\n```shell\nwget https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/stable-virtio/virtio-win.iso\n```\n- Latest (in the case if Stable does not work.)\n```shell\nwget https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/latest-virtio/virtio-win.iso\n```\n\nAfter downloading the right ISO, attach it to your KVM/QEMU instance and then reboot the machine. After the reboot, go to `My Computer` and run the iso to install the proper drivers.\n\n### Offline\n\n* * *\n* * *\n* * *\n\n## Notes\n\n- eXtremeSHOCK Optimization / Post Install Scripts located below\n  - [Repo](https://github.com/extremeshok/xshok-proxmox)\n\n## Style\n\n- Dark Mode Theme for Proxmox\n  - Installation Script located here: [Github PVEDiscordDark](https://github.com/Weilbyte/PVEDiscordDark)\n  - The script alters the css / js , so that the panel has a \"Dark\" / Discord theme base.\n  - `bash <(curl -s https://raw.githubusercontent.com/Weilbyte/PVEDiscordDark/master/PVEDiscordDark.sh ) install`\n\n## Podcast\n\nGeneral jokes/memes about the proxmox and general weird methods. \nWe were trying to find a cute and creative way to introduce the vast realm of virtual machines.\n\n### Jokes\n\nDock Swarm\n\n```yaml\n# Setting up Docker Swarm on multiple Proxmox VE containers\n#> Ziggy9263 (@jzanecook), h0lybyte (@KBVE)\n\n## 1. Introduction\n\n### 1.a. Crack your head against a wall\n\n#> The important thing to remember is that any all things that go horribly wrong can and will do so.\n#> Ziggy9263, from the docker container he has found himself trapped in\n\n#In order to begin working on a Docker Swarm, first you need to brush up on the general concepts behind the entire premise of this system. There are no winners, and there are no losers, there are only those who have discovered the wonders of setting up Docker Swarm, and those who have wandered a little too close to the wonders and have developed a pus filled growth on their abdomen.\n\n#If you have begun emitting a yellowish bioluminescence from your fingertips or have developed a large green and cyan vein stretching from your lower cheek to your posterior, then this article is not for you, and it's too late.\n\n#Otherwise, if you've simply peered over the edge of this foreign landscape, not yet realizing that the brush you're walking through is toxic in nature due to the radiation left from previous swarms, then this article may come in handy in your short lived traversal from bomb stricken wasteland to the maw of the amorphous creature you accidentally brought to your doorstep while typing `docker stack deploy`.\n\n#In the following sections, we'll go over the process of:\n#-> Setting up Proxmox VE (7.2.1)\n#-> Installing Proxmox Darkmode for Comfort\n#-> Setting up `vmbr1` for Internalized Networking\n#-> Setting up Traefik\n#-> Minimizing DUIs\n#-> Initializing a Docker Swarm\n#-> Creating Nodes and Keeping Order via Quorum\n#-> Creating Replicants and how to keep Rick Deckard off your ass\n#-> Creating Reverse Proxies for your Nodes\n\n### 1.b. Invest in your retirement fund\n\n#If you haven't already, it's important that you do before it's too late. This article, however, will not help you with that.\n\n## 2. Proxmox\n### 2.a. Setting up Proxmox VE (7.2.1)\n### 2.b. Installing Proxmox Darkmode for Comfort\n### 2.c. Setting up `vmbr1` for Internalized Networking\n\n## 3. Traefik\n### 3.a. Setting up Traefik (Version Number Here h0ly don't forget version number here version number don't forget)\n### 3.b. Minimizing DUIs\n\n## 4. Docker Swarm\n### 4.a. Initializing a Docker Swarm\n### 4.b. Creating Nodes and Keeping Order via Quorum\n### 4.c. Creating Replicants and how to keep Rick Deckard off your ass\n#In case you aren't in the know like cool guy Jones, Rick Deckard is from Bladerunner and he hunts stray replicants, the premise here don't let replicants go stray.\n### 4.d. Creating Reverse Proxies for your Nodes\n```\n","collection":"application","data":{"title":"Proxmox","description":"A complete open source software platform for virtualization management.","tags":["vm","containers","host","network","netplan","ovh","ubuntu"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1558494949-ef010cbdcc31?fit=crop&w=1400&h=700&q=75"}},{"id":"pterodactyl.mdx","slug":"pterodactyl","body":"\n\nimport Github from \"@w/Github.astro\";\nimport VideoComponent from \"@c/Element/Video/Video.astro\"\nexport const components = { github: Github , video: VideoComponent };\n\n\n## Panel\n\n- The core of the panel is built with PHP, React and Go.\n\n* * *\n\n## Install\n\n- Docker Compose\n  - <Github src=\"data/pterodactyl/panel/panel-compose.yml\" description=\"The docker compose for the panel.\" />\n\n* * *\n\n## Wings\n\n- Wings installed via `docker`\n  - <Github src=\"data/pterodactyl/wings/wings-compose.yml\" description=\"The docker compose for the wings.\" />\n\n* * *\n\n## Eggs\n\n-\n\n* * *\n\n## Media\n\n- Techno Tim's Game Server with Pterodactyl + Docker\n    <VideoComponent iframe src=\"yt\" id=\"_ypAmCcIlBE\" description=\"Techo Tims Guide\" />\n- Pterodactyl Install Guide by Synthetic Everything\n    <VideoComponent iframe src=\"yt\" id=\"2mibJeaEq3Q\" description=\"Synthetic Guide\" />\n\n* * *\n\n## Notes\n\n-\n\n* * *\n","collection":"application","data":{"title":"Pterodactyl","description":"Game server management panel that runs servers in isolated docker containers.\n","tags":["technology","docker","vm"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1653730106221-290f07b3b2db?fit=crop&w=1400&h=700&q=75"}},{"id":"python.mdx","slug":"python","body":"\n## Information\n\n---\n\n## Install\n\n---\n\n## pip\n\n`pip` is the package manager for Python. \nIt is used to install and manage software packages written in Python. \n`pip` is included with most Python distributions, and it can be installed separately for other distributions.\n\nTo use `pip`, you need to know the name of the package you want to install. \nYou can find the name of the package by searching the Python Package Index (PyPI). \nOnce you know the name of the package, you can install it with the following command:\n\n```shell\npip install <$package_name>\n```\n\nReplacing the syntax of `<$package_name>` with the package you would like to install from the PyPI libraries.\n\nIn this example, we will look into the install of the `requests` package via `pip`.\n\n```shell\npip install requests\n```\n","collection":"application","data":{"title":"Python","description":"Python is a general-purpose, objected-oriented, high-level programming language.  It is known for its simplicity, readability, and versatility. Python is often used for web development, data science, machine learning, and artificial intelligence.","tags":["python","script","pip"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1526379095098-d400fd0bf935?fit=crop&w=1400&h=700&q=75"}},{"id":"rust.mdx","slug":"rust","body":"\n\n## Information\n\n\n## Cargo\n\n> TLDR; Cargo is a package manager for Rust that handles the dependencies, compiling and distribution. Cargo can publish your package to `crates.io` so that it can be used with other applications within Rust.\n\nTo get started with Cargo, see if you have Cargo installed via running `cargo` with the help flag:\n\n  - ```shell\n    cargo help \n    ```  \n    - For `ubuntu` you might need to run `sudo cargo help`.\n\n## Rust Cargo-Watch\n\n- ### Watch\n\n  - Cargo-Watch will watch over the current project's source code for changes and then run Cargo commands when they occur.\n  - This will make building and development easier!\n\n- ### Watch Install\n\n  - To install the cargo-watch, run this command below in shell on the dev operating system.\n\n    - ```shell\n        cargo install cargo-watch\n        ```\n\n- ### Watch Terms\n\n  - The default cargo watch that we are currently using is:\n\n    - ```shell\n        cargo watch -q -c -x run\n        ```\n\n## Guides\n\n- [The Rust Programming Language Book](https://doc.rust-lang.org/stable/book/title-page.html)\n\n> (From the Official Rust Lang Website)\n> This book assumes that you’ve written code in another programming language but doesn’t\n> make any assumptions about which one. We’ve tried to make the material broadly accessible\n> to those from a wide variety of programming backgrounds. We don’t spend a lot of time talking\n> about what programming is or how to think about it. If you’re entirely new to programming, you\n> would be better served by reading a book that specifically provides an introduction to programming.\n\n- [A Gentle Introduction to Rust](https://stevedonovan.github.io/rust-gentle-intro/)\n\n> The aim of this tutorial is to take you to a place where you can read and write enough Rust to\n> fully appreciate the excellent learning resources available online, in particular\n> [The Book.](https://doc.rust-lang.org/stable/book/title-page.html)\n> It's an opportunity to try before you buy, and get enough feeling for the power of the language to want to go deeper.\n\n- [Rust 🦀 and WebAssembly 🕸](https://rustwasm.github.io/book/)\n\n> This small book describes how to use Rust and WebAssembly together.\n\n- [Cookin' with Rust](https://rust-lang-nursery.github.io/rust-cookbook/intro.html)\n\n> This Rust Cookbook is a collection of simple examples that demonstrate good practices to accomplish common\n> programming tasks, using the crates of the Rust ecosystem.\n\n## MicroService\n\nThis is a quick repo / guide on a Rust MySQL Microservice!\n\n- Official [Repo](https://github.com/second-state/microservice-rust-mysql)\n\nWe plan to extend Strapi via the Rust MySQL Microservices ^ example above but isolating layers, such as login, register, ect..\n\n## Install\n\n**On Linux or MacOS or (WSL on Windows)**:\n\n- [According to Chapter 1.1 from the Official Book](https://doc.rust-lang.org/stable/book/ch01-01-installation.html) to install rust you can use the following script:\n\n- Command to install via `curl`\n\n  - ```shell\n    curl --proto '=https' --tlsv1.3 https://sh.rustup.rs -sSf | sh\n    ```\n\n  -> The command downloads a script and starts the installation of the `rustup` tool, which installs the latest stable version of Rust. You might be prompted for your password. If the installation is successful, the following line will appear:\n    -> ```Rust is installed now. Great!```\n  - You will also need a *linker*, which is a program that Rust uses to join its compiled outputs into one file. It is likely you already have one. If you get linker errors, you should install a C compiler...\n\n**On Windows**:\n\n- [Reference the Book's Chapter 1.1 'Installing `rustup` on Windows' section](https://doc.rust-lang.org/stable/book/ch01-01-installation.html#installing-rustup-on-windows)\n\n## Rust Web\n\n- There are a couple options for running a HTTP server in Rust.\n\n- ### Axum\n  \n  - Axum is an ergonomic and modular Rust web application framework.\n  - [Github Repo](https://github.com/tokio-rs/axum)\n  - Axum can be extended through Tower, which is an ecosystem of middleware, services and utilities\n\n- ### Actix\n\n  - Actix is TO:DO\n\n- ### Rocket\n\n  - Rocket is TO:DO\n\n## Rust Applications\n\n- ### Youki\n\nYouki is an Open Container Initiative runtime specification library written in Rust.\n\nOfficial [Youki Repo](https://github.com/containers/youki)\n\nThere are some issues with some devices within `CGroups v2` that should be noted.\n\nSince youki is a low-level runtime, its recommend that you combine it with a high-level runtime, such as Docker / Podman.\n","collection":"application","data":{"title":"Rust","description":"A language empowering everyone to build reliable and efficient software.","tags":["development","programming","rust","language","compilation"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1565153907400-7e01a9ab25f3?fit=crop&w=1400&h=700&q=75"}},{"id":"rustdesk.mdx","slug":"rustdesk","body":"\n# RustDesk\n\n## Information\n\n### Referance\n\n* * *\n\n# Download\n\nThe RustDesk client is available for most of the operating systems and a beta web client is still in development.\n\n## Client\n\n### Windows\n\n### MacOS\n\n### Ubuntu\n\n* * *\n\n## Server\n\nIt is recommended that you self-host and there are a couple options for the RustDesk server that we can reference. \n\n### Docker\n\nThe official docker image is hosted on the dockerhub under [rustdesk/rustdesk-server](https://hub.docker.com/r/rustdesk/rustdesk-server). The","collection":"application","data":{"title":"RustDesk","description":"A remote desktop application that allows access, control and maintenance","tags":["rdp","management","remote"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1603969409447-ba86143a03f6?fit=crop&w=1400&h=700&q=75"}},{"id":"ryujinx.mdx","slug":"ryujinx","body":"\n## Information\n\nRyujinx is an open-source Nintendo Switch emulation software that can be used to play Switch games on Windows.\nTo set up `Ryujinx`, you will need to download the emulator from the Ryujinx website.\nOnce you have downloaded the emulator, you will need to extract the files to a location of your choice.\nAfter extracting the files, you can open Ryujinx and start playing your Switch games.\n\n## Install\n\nWe will break down the process of installation on various operating systems, but it should be noted that this is best used on Windows.\n\n### Choco\n\nInstalling RyuJinx through `choco` is the best option because it will keep the software up to date and make the install/removal very painless and easy!\nIf you do not have `choco` installed, then head over to our [choco documentation file](https://kbve.com/application/choco) for more information.\nThe official package repo for Ryujinx is located [here at Chocolatey](https://community.chocolatey.org/packages/ryujinx) if you need to verify or see their documentation.\n\nThe best way to install it would be to include the Desktop shortcut parameters!\nHere is the quick command to get it installed and running:\n\n```shell\nchoco install ryujinx --params \"/DesktopShortcut\"\n```\n\nThis will have the application installed and you can run it from your desktop! \nSee how easy this was! Makes it so much faster!\n\n### Windows\n\nWe really recommend that you install the software via `choco` as it will save you time, effort and energy! If you need help check, come to our Discord or IRC.\n\nHere are the steps you would take to setup and install RyuJinx directly for Windows:\n\n1.  Download the Ryujinx emulator from the Ryujinx website.\n\t1. (a) You can choose to download the software from the Github repo as well! \n\t2. (b) Make sure you have your drivers updated!\n2.  Extract the files to a location of your choice.\n3.  Open Ryujinx.\n4.  Click on the \"File\" menu and select \"Add Game.\"\n5.  Browse to the location of your Switch game files and select them.\n6.  Click on the \"Open\" button.\n7.  Your game will now start playing in Ryujinx.\n\nAfter you get the software installed, double check it by running it and seeing if there are any errors.\n\n### Mac\n\nWe do not have any notes yet on the Mac install for this time. I will have to spend some time setting that up on my `m1`, however I been told that it is a pain and is not really worth the amount of time to invest.\n\n--- \n\n## Setup\n\nAfter installing the software, you will have to look into setting up the `RyuJinx` and for that we recommend using `RyuSAK`, which can be found [here at the RyuSAK repo](https://github.com/Ecks1337/RyuSAK/release).","collection":"application","data":{"title":"RyuJinx","description":"This educational purpose only document is about the experimental software that was written in C#!","tags":["emulation","software","gaming"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1612036781124-847f8939b154?fit=crop&w=1400&h=700&q=75"}},{"id":"simba.mdx","slug":"simba","body":"\n# Simba\n\n---\n\n## Information\n\nSimba software is an open source automation software designed for repeatable mouse/keyboard tasks that follow a generic linear timeline.\nThe software's primary functionality is locating colours / pixels within the screen of choice, then moving the mouse to click the x and y coordinates of the colour / pixel.\n\n---\n\n# Install\n\n---\n\n# SRL\n\nThe active repo for SRL is currently under [Villavu/SRL-Development](https://github.com/Villavu/SRL-Development)\n","collection":"application","data":{"title":"Simba","description":"An automation software design that scopes it target via color / BMP and extendable via image post-process spacial allocation.","tags":["automation","color","bot"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1620023593001-3394d6297aeb?fit=fill&fill=solid&fill-color=360036&w=1400&h=700&q=75"}},{"id":"strapi.mdx","slug":"strapi","body":"\n## Information\n\nStrapi, an open-source headless CMS written in NodeJS, is the ultimate solution for creating and managing your content in a modern and flexible way through an user-friendly admin panel.\nYou can customize every aspect of your content model and logic, and choose from a variety of databases to store your data. \nFurthermore, Strapi also supports both RESTful and GraphQL APIs, so you can easily connect your content to any front-end framework or platform you prefer.\nWhether you want to build a blog, a portfolio, an e-commerce platform, or anything else, Strapi can help you achieve your goals with ease and elegance while delivering your content faster and easier.\nThis document is design to help provide an all-inclusive breakdown of Strapi from handling the database, installation, upgrades to scaling and custom plugins. We recommend going over the different setup(s), starting with running it locally and then see how you would like to run the application.\n\n* * *\n\n## Install\n\n> Before the installation process, we recommend setting up the [database](#database).\n\nWe are currently running Node v18.x for Strapi 4.10.x but if you wish to run Strapi under Node v16.x then use Strapi version 4.0.x to 4.3.8. According to their documents, if you are planning to run the SQLite database, then you will also need to have python installed and configured. \n\nThe KBVE way of installing and operating Strapi would be with Docker via a Strapi image. However if you want to run it without any extra virtualization, then do it via locally. \n\n### Local Install\n\nThis is a simple way to run Strapi as a local installation! The command to get started is: \n```shell\nyarn create strapi-app my-project --quickstart\n```\nAfter the creation process is done then head over to: `http://localhost:1337/admin` and create your first admin account. Afterwards you can mess around with the collections and get a better feel! Skip down to the `Collections` part of this documentation for more information.\n\n### Docker Install\n\nThe KBVE way of getting Strapi up and running would be to run a docker-compose, which would pull our Strapi image, MariaDB/MySQL for the database and configure the networking / storage within your docker swarm. If you need help setting up docker and the docker swarm, then we suggest you head over to our [Docker application notes section](https://kbve.com/application/docker) for more information.\n\n## Update\n\nThere are a couple ways of updating your Strapi instance, including using docker, yarn or manually. \n\n* * *\n\n## Database\n\nStrapi supports various databases.\n\n### MySQL\n\n> Find additional information on [MySQL](https://kbve.com/application/mysql/)\n\nBelow are the generic commands for setting up a `strapi` database. \n\n- `CREATE DATABASE strapi;`\n- `CREATE USER 'strapi'@'localhost';`\n- `GRANT ALL PRIVILEGES ON strapi.* TO 'strapi'@'localhost';`\n- `ALTER USER 'strapi'@'localhost' IDENTIFIED WITH mysql_native_password BY 'strapi';`\n- `FLUSH PRIVILEGES;`\n- `EXIT;`\n\n#### What to do if you run into the `Error: ER_NOT_SUPPORTED_AUTH_MODE: Client does not support authentication protocol requested by server; consider upgrading MySQL client` error?\n\n> In this scenario, you probably did what I did and altered the password with `ALTER USER 'strapi'@'localhost' IDENTIFIED BY 'strapi';` which is incorrect, insert `WITH mysql_native_password` in there and you should be good afterwards.\n\n* * *\n\n## Security\n\n### Captcha\n\n#### hCaptcha\n\n- In the .env include the secret_key , which you can obtain from hCaptcha via their settings for the account.\n- Note: HCAPTCHA=secret_key\n\n* * *\n\n## i18n\n\n- Ref [1](https://docs.strapi.io/developer-docs/latest/plugins/i18n.html)\n- Ref [2](https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/i18n)\n- 10/11/2022 - R&D within the i18n and utilizing it on the front-end.\n- Issue [#73](https://github.com/KBVE/kbve.com/issues/73)\n\n* * *\n\n## Functions\n\n### Login\n\n- The login for Strapi can be either a combination of `username + password` or `email + password`. Both `username` and `email` are passed through as an entity defined as `indentifier`. After the login action is sucessful, the API returns two variables:\n  - User:\n    - This is the `user` data that contains the following information:\n      - `username`\n      - `userid`\n      - `email`\n      - There are other fields of information that are customizable and the schema can be referenced in our `API`.\n  - JWT:\n    - The JWT (`jwt` or `token`) is an extremely important piece of data that contains the authentication for the user. We are currently reviewing how we should go about storing this token and utilizing it later down the line.\n\n### Register\n\n- For registration, we ask the user to submit a generic form that contains the following variables:\n  - Username\n    - If the `username` is taken, Strapi does return an error back as a response stating that the `username` was taken.\n  - Email\n    - If the `email` is taken and we disable `multi-account` on the Strapi backend, then it will return an error back as a response stating that the `email` was taken.\n  - Password\n    - Password is encrypted and stored as a hashed variable within the database.\n  - Security (as a Captcha via hCaptcha)\n    - After the user solves the captcha, an one-time code is generated, which is passed along as a `token`. If the captcha is wrong or missing, the Strapi returns an error.\n- We still need to take the errors that `Strapi` sends back , parse and then render them client side.\n\n## Notes\n\n### Log\n\n#### Journal\n\n##### 2023-04-10\nUpdating the notes with a bit more information and organizing.\n\n##### 2023-03-20 \nUpdating to 4.5v and then re-organizing the notes!\n","collection":"application","data":{"title":"Strapi","description":"🚀 Strapi is the leading open-source headless CMS. It’s 100% JavaScript, fully customizable and developer-first. This document will provide you with everything you need to install and maintain your Strapi instance.","tags":["api","cms","nodejs"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1622279488885-d831e8e76cef?fit=crop&w=1400&h=700&q=75"}},{"id":"terraform.mdx","slug":"terraform","body":"\n### References\n\n- [Terraform The Hard Way](https://github.com/AdminTurnedDevOps/Terraform-The-Hard-Way)\n\n- [TerraForm Sentry](https://github.com/jianyuan/terraform-provider-sentry)\n\n- [Awesome Terraform](https://github.com/shuaibiyy/awesome-terraform)\n\n- [Terraform Scalable Self Hosted Github Action](https://github.com/philips-labs/terraform-aws-github-runner)\n\n### Wrapper\n\n- [PreTF](https://github.com/raymondbutcher/pretf)\n\n- [TerraformJS](https://github.com/mdawar/terraformjs)\n","collection":"application","data":{"title":"Terraform","description":"terraform baby! WIP","tags":["technology","api","iaas","devops"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1524439188326-e47322d1cef2?fit=crop&w=1400&h=700&q=75"}},{"id":"traefik.mdx","slug":"traefik","body":"\nimport Github from \"@w/Github.astro\";\nexport const components = { github: Github };\n\n\n## Traefik\n\n* * *\n\n- Traefik is a cloud-hybrid reverse proxy and load balancer that makes deploying, configuring and integrating infrastructure components easy and automatic.\n\n* * *\n\n## Install\n\n- Docker Compose\n  - There should be an acme.json file that you create and pass through the docker with the permission of chmod 600.\n  - Furthermore, there are two more files that you will have to configure and pass through before launching the traefik container. We provided them in the #config section below.\n  - <Github src=\"data/traefik/docker-compose.yml\" description=\"This is a docker compose for traefik.\" />\n  \n* * *\n\n## Config\n\n- Traefik.yml Example\n  - <Github src=\"data/traefik/traefik.yml\" description=\"This the primary config for our traefik.yml\" />\n- Config.yml Router Example\n  - <Github src=\"data/traefik/config.yml\" description=\"This the router config for our reverse proxy. Written by Techo Tim originaly and modified by our team.\" />\n\n* * *\n\n## Kubernetes\n\n- Patching Traefik on k3s cluster\n  - We want to find the instance of where traefik is running. Running `sudo kubectl get all -o wide --all-namespaces` should display all your containers, look for traefik.\n  - Patch\n\n    - ```shell\n      sudo kubectl patch svc traefik -n kube-system -p '{\"spec\":{\"externalTrafficPolicy\":\"Cluster\"}}'`\n      ```\n\n  - std output should be `service/traefik patched`\n\n- Helm Charts\n\n  - ```shell\n    helm repo add traefik https://helm.traefik.io/traefik\n    ```\n\n    - **Sucess**: std output should be\n\n      - ```shell\n        \"traefik\" has been added to your repositories\n        ```\n\n  - ```shell\n    helm repo update\n    ```\n\n- Traefik Middleware for Kubernetes\n  - Middleware kind should be isolated for performance and security reasons.\n    - Auth - Kind: Middleware\n      - Example:\n\n        - ```yaml\n          apiVersion: traefik.containo.us/v1alpha1\n          kind: Middleware\n          metadata:\n            name: longhorn-auth\n            namespace: longhorn-system\n          spec:\n            basicAuth:\n              secret: authsecret\n          ```\n\n          - The middleware should be saved as a yaml / yml file and applied using kubectl.\n    - Auth - Kind: Ingress\n      - Calling the `longhorn-auth` in the `Ingress` via `annotations`:\n        - Example:\n\n          - ```yaml\n                      \n              apiVersion: networking.k8s.io/v1\n              kind: Ingress\n              metadata:\n                name: longhorn-ing-traefik\n                namespace: longhorn-system\n                annotations:\n                  externalTrafficPolicy: Local \n                  kubernetes.io/ingress.class: traefik\n                  traefik.ingress.kubernetes.io/router.middlewares: longhorn-system-longhorn-auth@kubernetescrd\n                  ingress.kubernetes.io/whitelist-x-forwarded-for: \"true\"\n                  \n              spec:\n                rules:\n                - host: \"x.kbve.com\"\n                  http:\n                    paths:\n                    - path: /\n                      pathType: Prefix\n                      backend:\n                        service:\n                          name: longhorn-service-provider\n                          port:\n                            number: 8000\n\n\n            ```\n\n          - In our PoC above, we see that the middleware is referenced as:\n\n            ```yaml\n                traefik.ingress.kubernetes.io/router.middlewares: longhorn-system-longhorn-auth@kubernetescrd\n            ```\n\n            Its important to note the namespace of the middleware, `longhorn-system` , before calling the middleware's name. This is to let the crd know where the middleware is located.\n\n* * *\n\n## Notes\n\n[According to the notes on Traefik & Kubernetes](https://doc.traefik.io/traefik/providers/kubernetes-crd/)\nwe first need to install the Resource Definitions and RBAC into `kubectl` by running the following commands:\n\n```shell\n# Install Traefik Resource Definitions:\nkubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.8/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml\n\n# Install RBAC for Traefik:\nkubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.8/docs/content/reference/dynamic-configuration/kubernetes-crd-rbac.yml\n\n```\n\nAfter this installation, we'll have a set of [Custom Resource Definitions](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\nwhich should have the following benefits:\n\n- The usage of `name` and `namespace` to refer to another Kubernetes resource.\n- The usage of [secret](https://kubernetes.io/docs/concepts/configuration/secret/) for sensitive data (TLS certificates and credentials).\n- The structure of the configuration.\n- The requirement to declare all the [definitions](https://doc.traefik.io/traefik/reference/dynamic-configuration/kubernetes-crd/#definitions).\n\nSee the list of CRDs in the dedicated [routing section](https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/).\n\nThe biggest thing we need from this is the ability to add the [BasicAuth](https://doc.traefik.io/traefik/middlewares/http/basicauth/) plugin.\nThis plugin (which is what we tried to reference before with the `auth@file` line) uses an htpasswd password to block incoming traffic to the pod.\n\nThis will require setting up an IngressRoute (which is a specific Kubernetes resource added by the Traefik Resource Definitions) with settings to specify\nwhat the middlewares are. [Find more info on the Traefik Middlewares Here](https://doc.traefik.io/traefik/middlewares/overview/)\n\n* * *\n\n\n## Cloudflare\n\nThese are notes on integrating `Cloudflare` with `Traefik`, including automating some of the actions so that you may not have to repeat them.\n\n### Acme Docs\n\n[Official Docs](https://go-acme.github.io/lego/dns/cloudflare/#api-tokens)\n\nAccess the API Tokens directly from [Cloudflare Profile](https://dash.cloudflare.com/profile/api-tokens)\n\nCommon environmental variable names and their purpose:\n\n- `CF_API_EMAIL` - The Cloudflare account holder's email.\n- `CF_API_KEY` - The Cloudflare API key.\n- `CF_DNS_API_TOKEN` - The API token with `DNS:Edit` permission.\n- `CF_ZONE_API_TOKEN` - The API token with `Zone:Read` permission.\n","collection":"application","data":{"title":"Traefik","description":"A cloud native application proxy that utilizes a modern HTTP reverse-proxy and load balancer.","tags":["networking","lb"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1524419986249-348e8fa6ad4a?fit=crop&w=1400&h=700&q=75"}},{"id":"unity.mdx","slug":"unity","body":"\n## Unity\n\n- Unity is a cross-platform software engine that focuses on developing games, apps and animation for desktop, mobile, console and virtual reality platforms.\n- The primary scripting language for the engine is `C#` and can be extended through a various collection of libraries and plugins.\n\n---\n\n## Services\n\nThere are several products that Unity offers ontop of their game engine, including DevOps, Advertising and Hosting services.\n\n---\n\n## Header\n\n- Right click and create empty\n- Name it below : (Replace HeaderName with the name you would want)\n\n```shell\n---> HeaderName\n```\n\n---\n\n## Scene\n\nEvery project starts with a scene and are a fundamental concept in Unity game / application development.\nThey are self-contained units that contain all of the game objects, components, and data for a particular game level.\nScenes can be loaded and unloaded at runtime, which allows developers to create games with multiple levels or to create games that can be customized by the player.\n\nWhen you create a new Unity project, you are given a default scene that contains a camera and a directional light.\nYou can add additional game objects to this scene by dragging them from the Assets window into the Scene view. \nFurthermore, you can also create new game objects by using the Create menu in the Hierarchy window.\n\nOnce you have created your game objects, you can add components to them.\nComponents are scripts that add functionality to game objects.\nFor example, you can add a Rigidbody component to a game object to make it move around in the world.\nYou can also add a Collider component to a game object to make it collide with other game objects.\n\nWhen you are finished creating your game objects and adding components to them, you can save your scene by clicking the Save button in the top-left corner of the Unity Editor.\nYou can also save your scene by pressing `Ctrl+S`.\n\n### Async Scene\n\nWhen switching between the scenes or loading multiple scenes, we recommend utilizing the asynchronous scene loader through a custom management script.\nThis will allow you to load complex levels while not impacting performance too greatly.\n\n---\n\n## WebGL\n\nA breakdown of WebGL for the Unity game engine!\n\n### WebGL Information\n\nWhen converting a project over to WebGL, there are a couple extremely important steps that you might have to take to prepare for an automated pipeline and distribution.\nThe most important step is to make sure that you have the HTML5/WebGL module for the specific Unity version installed and ready.\nAfter that check the resolution, an example would be 800 x 600 but you can set it to your project's desired scope.\nNext you want to make sure to check the box, `Run in background`, and save it. This should change the `runInBackground` inside of `ProjectSettings\\ProjectSettings.asset` from 0 (false) to 1 (true).\nFinally double check that you have the right compression methods enabled or in some cases, like Github Pages, disabled completely.\n\n---\n\n## Python\n\nThe official notes and changelogs for the python integration inside of unity can be found on their [website](https://docs.unity3d.com/Packages/com.unity.scripting.python@7.0/changelog/CHANGELOG.html).\n\n---\n\n## Pipeline\n\nUnity has three core concepts for their render / build pipeline, which takes all your source code within your project and builds a finished product for various operating systems.\n\n\n### CICD\n\nFor continous integration and continous development within the Unity Pipeline, we recommend going to our [git](https://kbve.com/application/git/#unity) for information.\n\nThe notes for Github Actions / Circle CI within Unity and the general scope of the project have been migrated to the Git documentation.\n\n---\n\n## API\n\nPart of building out the game and the multiplayer is to have a reference point for each player, we decided the best way to do that would be through JWTs / web tokens.\n\n### Multiplayer\n\nThese are our notes and information regarding multiplayer\n\n- Colyseus.io seems like the first engine of choice that we might use.\n\n  - Github [Repo](https://github.com/colyseus/colyseus)\n  - Colyseus.io [Docs](https://docs.colyseus.io/colyseus/)\n\n- Reference Links\n  - Chowdera [1](https://chowdera.com/2021/05/20210512110823582J.html)\n  - S1H [2](https://blog.s1h.org/colyseus-multiplayer-game/)\n\n### Strapi\n\nHere is a custom function to help you integrate `Strapi` into your application.\n\n> Hint: Since the function is an IEnumerator, we suggest wrapping it inside of a coroutine.\n\n```c#\n\nprivate IEnumerator LoginEnumProcess() //  [VOID]  -> {LoginEnumProcess()}\n    {\n        var user = new UserLoginData(); user.identifier = _text_Username.text;  user.password = _text_Password.text;\n            \n        //* {Request Header}\n            string jsonData = JsonUtility.ToJson(user);\n            var request = new UnityWebRequest(LoginURL, \"POST\");\n            byte[] jsonToSend = new System.Text.UTF8Encoding().GetBytes(jsonData);\n            request.uploadHandler = (UploadHandler)new UploadHandlerRaw(jsonToSend);\n            request.downloadHandler = (DownloadHandler)new DownloadHandlerBuffer();\n            request.method = \"POST\";\n            request.SetRequestHeader(\"Content-Type\", \"application/json\");\n            request.SetRequestHeader(\"Accept\", \"application/json\");\n\n            yield return request.SendWebRequest();\n\n            //? {y} -> Error\n            if(request.result != UnityWebRequest.Result.Success)    { Debug.Log(request.error);  yield break; }\n            else {\n            //! {y} -> Success  -> #NEXT    -> #WIP\n\n                JSONNode userData = JSON.Parse(request.downloadHandler.text);\n                Debug.Log(userData);\n                \n                GlobalValue.PlayerJWT = userData[\"jwt\"];\n                GlobalValue.PlayerEmail = userData[\"user\"][\"email\"];\n                GlobalValue.PlayerUsername = userData[\"user\"][\"username\"];\n\n                    // PlayerPrefs.SetString(\"jwt\", userData[\"jwt\"]);\n                    // PlayerPrefs.SetString(\"username\", userData[\"user\"][\"username\"]);\n                    // PlayerPrefs.SetString(\"email\", userData[\"user\"][\"email\"]);\n                    // PlayerPrefs.Save();\n            //? {y} -> Migrate load to Global Values? \n                Debug.Log(PlayerPrefs.GetString(\"username\"));\n                \n                \n                SceneManager.LoadScene(\"Base\", LoadSceneMode.Single);\n                yield break;\n                }\n        \n    }\n\n```\n\n\n### AppWrite\n\nAnother `API` that you can use inside of Unity is AppWrite but there is only an unofficial plugin for the integration.\nThus we suggest being careful if using it in a production environment.\n\n### Firebase\n\nFirebase integration with Unity makes it easy for developers to add these features to their games without sacrificing security.\nFor example, developers can use Firebase Authentication to allow users to sign in to their games with their Google, Facebook, or Apple accounts.\nThey can also use Firebase Realtime Database to store data in real time, such as the player's score or the current state of the game.\nThere are a couple other cool features included in the Firebase integration, such as using Firebase Cloud Messaging to send push notifications to players, such as notifications about new levels or in-game events.\n\nThe three core benefits with using Firebase are the `Ease of use`, `Scalability` and `Security`:\n- Ease of use: Firebase is designed to be easy to use, even for developers who are new to cloud services.\n- Scalability: Firebase can scale to support even the most demanding games.\n- Security: Firebase is a secure platform that uses industry-standard security measures to protect your data.\n\nThe repository for the Firebase Unity SDK is located [here](https://github.com/firebase/firebase-unity-sdk)\n\nFurther documentation and information can be found at the [Google Firebase Docs for Unity](https://firebase.google.com/docs/unity/setup)\n\n#### Firebase Setup\n\nThe setup has a couple `prerequisites` that you will need to ensure before going deeper into the integration.\n\n- Unity prerequisities for Firebase.\n- - KBVE recommends 2021.3 LTS or higher.\n- - Make sure that your unity project is Unity 2021.1 LTS or higher, while it does support 2019.1 LTS, in 2024, it will become deprecated.\n\n- Apple -> Unity prerequisites for Firebase.\n- - KBVE recommends xCode 14.x or higher.\n- - xCode 13.3.1 or higher.\n- - CocoaPods 1.10.x or higher.\n- - iOS target of v11 or higher.\n- - tvOS target of v12 or higher.\n\n- Android\n- - Android API level 19 or higher.\n- - KBVE Recommends 23 or higher, if you are using cryptography.\n\n### Steam\n\nThese notes are still a work in progress, but I will try my best to continue to improve them as I am building out the Steam API for the Unity/React Project.\nOfficial [Repo](https://steamworks.github.io/installation/#unity-instructions)\n\n#### Steam Setup\n\nIt seems that before you start to integrate SteamWorks / Steam API / SteamWorksNET , you need an active SteamWorks developer account. You can create the account [here](https://partner.steamgames.com/newpartner/?)\n\n`Legal Name`\n\nSteam Defines it as\n\n> This is really, really important to enter correctly. Carefully read all instructions below. You will be unable to release your product via Steam until this name matches all records.\n> The name you enter below must be the legal entity that owns or has rights to publish the game, software or video (\"content\") and is the legal entity that will be signing the Steam Distribution Agreement. The legal name you enter here must match the name as written on official documents with your bank and on United States IRS tax documents or foreign tax documents if applicable. You will need to enter this name again as your bank account holder and the legal name associated with a tax payer identification number in the following steps.\n> If you don’t have a company name and you are the sole owner of your content, please fill in your full name as the Legal Name and your own address as Street Address. If you co-own the content with other individuals, you must form a legal entity to own and receive payments for your content.\n> The Legal Name here is for internal use. If you have a DBA or 'friendly name' that you wish to show to customers on your store page, you will be able to enter that separately when creating your store page.\n\nThis is an extremely important step, we advise that you consult with your legal parties if there are any major issues.\n\nWe recommend that, if you are a US Citizen, have all our personal information (Tax, Bank, KYC, ect...) ready before completing the application. Furthermore, there is a $100 fee for the application.\n\n#### Steam Launch\n\nWell we applied as of 11/23/2022 , so we will wait until everything is confirmed and then move forward with this.\n\nOkay so we been approved, now you should have 1 application credit in your Steamworks profile! This is where you then create your application, using that application credit that you paid $100 for!\n\nPlace your application name and then go through the form, it will then spit out some interesting variables:\n\n> Requesting AppID For: KBVE.com RogueJester\n> Created package \"KBVE.com RogueJester Developer Comp\" with ID 802XXX\n> Created package \"KBVE.com RogueJester for Beta Testing\" with ID 802XXX\n> Created package \"KBVE.com RogueJester\" with ID 802XXX\n> Added auto-grant to publisher \\*XXX\n> Created store item '518XXX'\n> Created store package for store item '518XXX'\n\nYou should keep this information safe and as a reference step.\n\n---\n\n## Plugins\n\nCollection of plugins for Unity game engine.\nWe want to include as many reference points and notes for the plugins that we are currently using.\n\n### Vuplex\n\nThis is a 3rd party plugin provider for Unity, that extends out the webview components for cross-platform compatibility through their own object-based library.\n\n#### Vuplex Errors\n\nThese are reference points for common errors within the Vuplex libraries / eco-system.\n\n##### Vuplex Resources\n\nLoading multiple webview components within a single scene can cause a spike within the client's CPU/RAM, thus it is recommended to de-sync / destroy or de-activate any un-used Canvas. Furthermore, only activate the GameObject when the player is within a set proximity to the object through the Unity's Collider system via event triggers.\nVuplex does run an instance of a chromium browser and that can lead to memeory and cpu leaks.\n\nAn example of this would be to declare the GameObject, add collision and then hook it a simple trigger script, like this:\n\n```c#\n\n    public GameObject webviewObject;\n    [SerializeField] private bool EnablePlayerWebview;\n\n    private void OnTriggerEnter(Collider other)\n    {\n        if(other.CompareTag(\"Player\") && EnablePlayerWebview) { webviewObject.SetActive(true);   }\n\n    }\n\n    private void OnTriggerExit(Collider other)\n    {\n        Debug.Log(\"Exiting\");\n        webviewObject.SetActive(false);\n    }\n\n```\n\n##### Vuplex Errors\n\n- Click and scroll not working : [Case 1]\n\nThere could be multiple reasons why click/scroll might not be functional, depending on the operating system, AR/VR tool kits and the Unity's input system.\nWhen defusing the situation, we recommend build multiple test cases with all components mapped out and then using `Debug.Log` to check through all the variables at play.\nWe been in situations where a foot of a humanoid object was not tagged as a `Player`, thus causing the whole collision engine to be off and not registering the functionality within a scene.\n\n\n\n### UCC\n\nUltimate Character Controller was the plugin of choice when doing RSDD aka rapid self-destructive development.\nOfficial Documentation [Link](https://opsive.com/support/documentation/ultimate-character-controller/). It is over 300 pages and covers the controller and its interaction within the unity environment.\nAccording to Opsive, their UCC is a professional and kinematic character controller that is designed for flexibility, modularity and performance; we consider it an \"AIO\" or \"All-In-One\" library.\n\n#### UCC URP\n\nGrab the invoice number from the plugin purchase and head over to [OPSive Downloads](https://opsive.com/downloads/) with it.\nAfter placing the invoice number into the system, it will give you download integrations for external plugins.\n\n\n#### UCC Asset Store\n\nOfficial [Asset Store](https://assetstore.unity.com/packages/tools/game-toolkits/ultimate-character-controller-233710).\nLast Release Date: 3.0.3 - Nov 24, 2022\n\n\n#### UCC Reference\n\n[Opsive Video Collection](https://opsive.com/videos/?pid=923)\n[First Person Character Creation](https://www.youtube.com/watch?v=EAuS_0OxyrA)\n\n\n#### UCC Character\n\nThe core of the UCC, Ultimate Character Controller, would be the Character model and its interactivity within the `Scene`, thus these notes are for referencing through the plugin and movement, collision, motion, gravity, abilities and more for the `Humanoid` / `Character`.\n\n\n### UCCIS\n\nThe `3DUnity` gateway layer will utilize the `UCC Inventory System` , which we can refer to as `UCCIS`, is an inventory system that was designed by Opsive and extended by our `3DUnity`.\n\n#### UCC Inventory\n\nThe `UCC Inventory` can be broken into modules, that we will refer to as:\n\n- Inventory\n- Item\n  - Action (Item)\n  - Object (Item)\n- Attributes\n- Currency\n- Crafting\n- Input\n\nThere are more modules within the system but v3 was released in late November 2022 and we still have to read through the notes/documentation && create test cases for each of the additional modules.\n\n#### UCCIS Attributes\n\nThe `Attributes` can be referenced throughout the `engine` and are designed to `override, inherit or modify` the value of another attribute; `Attributes` can be utilized to create variants (`Override`, `Inherit` or `Modify`) of Item Definitions.\n\nThe `Attributes` can be broken down into three variant types: (As referenced in the documentation)\n\n- Override: Overrides the `parent` attribute value of the given object.\n- Inherit: Inherits the `parent` attribute value of the given object.\n- Modify: Uses an expression to compute a value that is dependent on the “parent” attribute or any other attribute in the same collection.\n\n#### UCCIS References\n\n[Asset Store](https://assetstore.unity.com/packages/tools/game-toolkits/ultimate-inventory-system-166053)\n[Inventory Docs](https://opsive.com/support/documentation/ultimate-inventory-system/)\n\nVideo Tutorials\n\n[Video Part 1](https://www.youtube.com/watch?v=-AqJ3-BXS70)\n[Video Part 2](https://www.youtube.com/watch?v=m0Z-wPFkM9w)\n\nThe two part video tutorial goes through a UCC / Inventory integration.\n\n\n### React\n\n- For React and Unity integration, we recommend going to our [React](https://kbve.com/application/javascript/#react) application page.\n\n### Steam Plugin\n\nWe moved the Steam into their own [notes](https://kbve.com/application/unity/#steam)\n\n### SimpleJSON\n\n- SimpleJSON is a plugin for JSON parsing in C#.\n- Official [Repo](https://github.com/Bunny83/SimpleJSON)\n\n### Modular AI\n\nModular AI helps design the behavior of GameObjects within Unity.\nThe official [Modular AI repo](https://github.com/Kitbashery/Modular-AI)\n\n### Hey Area Object Spawner\n\nA simple tool that helps procedural generation of objects within an area.\nThe plugin's official [repo for Hey Area Object Spawner](https://github.com/JahnStar/Hey-Area-Object-Spawner)\n\n### Hierarchy 2\n\n- Hierarchy 2 helps organize the Unity UI.\n- Official Asset [Store](https://assetstore.unity.com/packages/tools/utilities/hierarchy-2-166483)\n\n### Premium\n\n- Premium plugins that have additional license or costs with them.\n\n### OneJS\n\n- Interpol between Javascript and Unity through JINT\n- This plugin is not open source but rather a private engine.\n\n### Webview\n\nUnity plugins that focus on webview by providing abstract layers that extend to controllers.\n\n### UniWebView\n\n- Adding Webview for iOS/Android can be easier through UniWebView, which is an open source web view component for mobile platforms.\n- Official [Repo](https://docs.uniwebview.com/api/)\n\n### Vuplex Plugin\n\nA commercial plugin that extends WebView components across all platforms, with major focus on AR/VR development kits for Oculus, Hololens and more.\nNotes on the [Vuplex](https://kbve.com/application/unity/#vuplex)\n\n### Corgi\n\nThese are KBVE notes and references for the `Corgi Engine` that was developed by More Mountains. Please note that the core of the Corgi Engine is a private / premium plugin for the Unity Engine, thus parts of our codebase / references will not work `out of the box`, as you will have to install the latest engine from the Unity Asset store.\nWe are currently test casing the corgi engine as the base for our 2D engine and then going to integrate it with our 2DUnity. As of early December 2022, we are test casing the pipeline with the engine as an underlay and restructuring our `2DUnity` as a gateway layer, a similar setup to our `3DUnity` and `UCC`.\n\n\n#### Corki Namespace\n\nThe `Corki` namespace is a KBVE extension of the `Corgi` namespace, adding custom gateway layers that make it easier to infer and interpolate among different APIs.\n\n\n---\n\n## Notes\n\n- Unity follows a duel release structure for their engine, a `latest` engine build and a `LTS` engine.\n- We recommend using the `LTS` as it has `Long Term Support`, which the company states for about 2 years, whereas the `latest` does not have any extended support.\n\n---\n\n## Errors\n\n- Common errors that users might face when working with Unity. This error log is meant to help keep track and may save some future developers a lot of time.\n\n### Error WebGL-000001FEA50EC410\n\n- ```shell\n    [.WebGL-000001FEA50EC410] GL_INVALID_FRAMEBUFFER_OPERATION: Draw framebuffer is incomplete\n  ```\n\n  - Solution: Turn on post processing on the Main Camera.\n\n### Error libil2cpp ERROR: Could not open Il2CppData/\n\nCurrently: There might be an issue when directly loading the Git LFS, so we will reference it via Github's media server.\nGit Notes can be found [here](https://kbve.com/application/git)\n\n### Error Dirty Branch\n\nThis will be a common error that you will see throughout `CI/CD` and comes from various issues, it can be from the wrong `guid` / `Seralization` or broken `ProjectSettings.asset`\n\nYou can ignore the dirty branch errors by using `allowDirtyBuild: true` within the `game-ci`, however this may cause problems down the line when the build gets more complex and additional platforms i.e `WebGl`, `Xbox`, ect...\n\n\n---\n\n## Unity Canvas\n\nThe Canvas is a GameObject within Unity that extends the UI elements and utilizes the EventSystem / Scene View.\n\n## Unity Assets\n\n- Unity Assets are a collection of media files.\n\n## 2D Assets\n\nThis is a collection of 2D assets that can be a great resource / reference for anyone looking to make a 2D game. We could migrate the 2D assets into their own reference later down the line.\n\n### PixelFrog\n\nOfficial [Itch](https://pixelfrog-assets.itch.io/)\n\nTreasure Hunters [Download](https://pixelfrog-assets.itch.io/treasure-hunters)\nKings and Pings [Download](https://pixelfrog-assets.itch.io/kings-and-pigs)\nPixel Adventure [Download](https://pixelfrog-assets.itch.io/pixel-adventure-1)\nPirate Bomb [Download](https://pixelfrog-assets.itch.io/pirate-bomb)\n\n## 2D\n\nThese are the notes for Unity's 2D engine and/or projects related to the 2D development cycle.\n\n## 2D Examples\n\nThe list below are open source projects that use Unity as their base for 2D/Retro style games.\n\n### Newbark\n\nOfficial [Repo](https://github.com/itsjavi/newbark-unity)\n\nItsjavi created an amazing open source proof-of-concept version of classic Pokemon (Red/Blue/Gold) that has been updated to Unity 2021 and has URP. It should be noted that there assets that might be infringing on intellectual property of Nintendo/Game Freak.\nOn a positive note, upon looking through his repo, I did stumble across a github bot known as [ImgBot](https://kbve.com/application/git/#imgbot), which provides image optimization via Git pulls.\n\nThe project uses: 2021.1.6f1 as the Unity Version and there seems to not include any pipeline/workflow, which might be because of the copyright issues.\nThe project also has [URP / Universal Render Pipeline](https://kbve.com/application/unity/#urp)\n\nI suppose it be interesting to take a look at their combat system, since the biggest issue that I see would be the usage of copyrighted material, but if you were to swap them out, then there might be a case to continue and `enhance` the repo? If anyone might be down to do this, please reach out to h0lybyte.\n\n### Kailius\n\nOfficial [Repo](https://github.com/Walkator/kailius)\n\nThis was another open source 2D repo that sparked my interest because it was built for the phone! It is a great reference point for a game written for Android by going through `input design` from dual perspective of UX/UI and internal scripting.\n\n#### Minor 2Ds\n\n[SpaceWalk Official Repo](https://github.com/Angel1841/Space-Walk)\n[FinalProject UnityW2022](https://github.com/DuncanBH/FinalPlatformerProject)\n","collection":"application","data":{"title":"Unity","description":"A 3D Game and App Engine to build cross platform software.","tags":["gaming","engine"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1519669556878-63bdad8a1a49?fit=crop&w=1400&h=700&q=75"}},{"id":"void.mdx","slug":"void","body":"\nimport Details from \"@w/Details.astro\";\nimport TabMenu from \"@w/TabMenu.astro\";\nimport TabData from \"@w/TabData.astro\";\nimport N from \"@n/N.astro\";\n\n\n<TabMenu first=\"general\" data={[\"cheatsheet\", \"system\", \"notes\"]}>\n<TabData tail=\"block\" data=\"general\">\n\n## Information\n\n## VOID\n\n- Virtualized Object Intelligence Daemon, or VOID, is an operator application that manages servers, nested machines and clustered botnets within an eco-system.\n  - Linux\n    - `void_install_ubuntu.sh` - (chmod 777) - Installation for Ubuntu 18+\n    - `void_install_debian.sh` - (chmod 777) - Installation for Debian 9+\n\n  - Windows\n    - `void_install_win11.exe` - (admin privilege) - Install for Windows 11\n\n  - Mac\n    - Mac M1 / M2* has an ARM based system, so it might have to be isolated from the intel macs.\n    - Expanding upon brew might be a better course for Macs*\n\n- Environs are entities that help balance and regulate the digital environmental.\n\n## TR33\n\n- `tr33` - (environ) - a collection of timers that handle micro tasks on the host machine.\n  - `tr33._04` - v4 is stable for Ubuntu 22 LTS, Debian 9, Windows 10/11.  \n    - `tr33._04.nginx.1_22` - Nginx\n    - `tr33._04.apache.1` - Disabled.\n  - `tr33._05YAML_.` - v5 is unstable but utilizes YAML, slated for deprecation by Q3 of 2024.\n  - `tr33._06JSON_.` - v6 is unstable but utilizes a JSON-based API for commands, slated for deprecation by Q4 of 2025.0\n  - `tr33._01`  - Deprecated - A rootkit that was designed and based upon various viruses.\n  - `tr33._02` - Deprecated.\n  - `tr33._03` - Deprecated.\n\n## S33D\n\n- `s33d` - (environ) - an application or library that expands upon torrent data seeding.\n  - `s33d._dna.` - commands that the host computer must run to enable specific future applications.\n    - `s33d._dna.WebRTC.1_3` - Enables WebRTC.\n  - `s33d._nfc.` - Compressed information that can be stored inside NFC. The format will take about 64 bytes.\n    - `68 74 74 70 73 3a 2f 2f 6e 2e 6b 62 76 65 2e 63 6f 6d 2f 64 6e 61 2f` - 23 bytes for the generic/default location of the seed, with 40 bytes left over for additional information regarding the application(s).\n\n## BL0CK\n\n- `bl0ck` - micro storage for host.\n  - `bl0ck.B64AES.` - Based 64 - AES compressed data block.\n  - `bl0ck.chain._` - Micro blockchain for the void system(s).\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n## R00T\n\n- `r00t` - (environ) - an embed that sits on-top of the operating system.\n  - `r00t` - Disabled as of `tr33._02` because the design induced significant flaws and exploits; uncle ben does not approve of such power for any man or s\n\n</TabData>\n\n<TabData data=\"cheatsheet\">\n\n## Cheatsheet\n\n</TabData>\n<TabData data=\"system\">\n\n## System\n\n</TabData>\n<TabData data=\"notes\">\n\n## Notes\n\nNotes on void.\n\n### Log\n\n- [ ] Include test examples of v0id.sh.\n- [ ] Install guide for v0id.sh.\n- [ ] Tutorial on setting up the v0id.sh system.\n\n#### Journal\n\n<Details data=\"2023-04-16\">Generic filler data for the v0id template</Details>\n\n### License\n\nNo License information yet on the v0id system at the current time.\n\n<N ns=\"ads\" template=\"mdx2\" id=\"ezoic\" />\n\n</TabData>\n</TabMenu>","collection":"application","data":{"title":"VOID","description":"Virtualization soft scripting for automation.","tags":["php","script"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1537158345907-c4fb34477bd6?fit=crop&w=1400&h=700&q=75"}},{"id":"watchtower.mdx","slug":"watchtower","body":"\nimport Github from \"@w/Github.astro\";\nexport const components = { github: Github };\n\n\n\n## Watchtower\n\n* * *\n\n## Install\n\n<Github\n  src=\"data/watchtower/docker-compose.yml\"\n  description=\"This is a docker compose we made.\"\n/> \n\n## Notifications\n\nIncase you need WatchTower to send Notifications, here is an example command that sets the environmental variables:\n\n\n```shell\ndocker run -d \\\n  --name watchtower \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -e WATCHTOWER_NOTIFICATIONS=email \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_FROM=fromaddress@gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_TO=toaddress@gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER=smtp.gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587 \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=fromaddress@gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=app_password \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_DELAY=2 \\\n  containrrr/watchtower\n```\n","collection":"application","data":{"title":"Watchtower","description":"A monitioring tool for automating Docker containers based upon image updates.","tags":["technology","vm","security","docker"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1602616213661-d1f469cd5a95?fit=crop&w=1400&h=700&q=75"}},{"id":"webserver.mdx","slug":"webserver","body":"## WebServer\n\n### Nginx\n\n### Apache\n\n## Tools\n\n### SpeedTest\n\n- Google's PageSpeed Insight\n  - [Official WebTool Location](https://pagespeed.web.dev/)\n    - The tool tests for both mobile and desktop, with couple options on the side.\n\n- TechEmpower Web Framework List\n  - [Official WebFrame](https://www.techempower.com/benchmarks/#section=data-r21)\n    - Performance is isolated by rounds, done annually.\n\n### CRT\n\nFinding the latest collection of certs for a domain.\n\n[CRT](https://crt.sh/?q=kbve.com&showSQL=Y)\n\n## Robots.txt\n\n- The purpose of this file to help the webmaster(s) provide pathways for bots to navigate the domain and internal sub-domains.\n","collection":"application","data":{"title":"WebServer","description":"Software that accepts requests via the HTTP/HTTPS protocol.","tags":["software","protocol"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1492515114975-b062d1a270ae?fit=crop&w=1400&h=700&q=75"}},{"id":"wireguard.mdx","slug":"wireguard","body":"\nimport Github from \"@w/Github.astro\";\nexport const components = { github: Github };\n\n\n## Wireguard\n\n* * *\n\n## Install\n\n- Docker Compose\n  - <Github src=\"data/wireguard/docker-compose.yml\" description=\"This is a docker compose for wireguard.\" />\n\n- Ubuntu Installation Guide\n  - Core Pre-Installation\n    - Make sure your docker install is setup! If you need more information, please visit our Docker application page.\n    - Check your firewall, are you using `ufw` , `iptables` or `nftables`\n  - Firewall\n    - Wireguard will be operating on the `UDP` port of `51820`.\n    - For: `ufw`\n      - To enable the port through `ufw` run `sudo allow 51821/udp`\n\n## Netmaker\n\n- Netmaker is a Wireguard automation application that handles self-hosted homelabs to small business / enterprise networking.\n- [Official Github Repo](https://github.com/gravitl/netmaker)\n\n## Netmaker Install\n\n- Advance install for netmaker allows the setup of a highly available installation within Kubernetes through helm.\n- The *default* settings may not install `wireguard` at the kernel level (for security reasons) and default to Postgres for storage.\n  - Not having kernel level wireguard may cause performance drops and they recommend that you install wireguard before beginning.\n- Helm Install Commands:\n\n  - ```shell\n    helm repo add netmaker https://gravitl.github.io/netmaker-helm/\n    helm repo update\n    ```\n  \n  - If you do not have `helm` or `kubernetes` setup, we recommend you visit our [kubernetes setup](https://kbve.com/application/k8s).\n- The storage of the certificates will be an issue for this netmaker cluster, they recommend two types of storage classes:\n  - `RWO` - `Read Write Once` - Storage instance where only a single node is allowed to access the storage volume at a time for read and write access.\n  - `RWX` - `Read Write Many` - Storage instance where many nodes can concurrently read and write to the storage volume.\n","collection":"application","data":{"title":"Wireguard","description":"A open source communication protocol that implements encrypted virtual private networks.","tags":["vpn","host","security"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1649429398909-db7ae841c386?fit=crop&w=1400&h=700&q=75"}},{"id":"zsh.mdx","slug":"zsh","body":"\n## Useful Links\n\n- [ZSH Shell Official Page](https://www.zsh.org/)\n- [Oh My Zsh Official Page](https://ohmyz.sh/)\n- [Powerlevel10K Repository](https://github.com/romkatv/powerlevel10k)\n- [One of the Best Tutorials by dev.to (Dec 2020)](https://dev.to/abdfnx/oh-my-zsh-powerlevel10k-cool-terminal-1no0)\n","collection":"application","data":{"title":"Oh My Zsh","description":"Oh My Zsh is a delightful, open source, community-driven framework for managing your Zsh configuration. It comes bundled with thousands of helpful functions, helpers, plugins, themes.\n","tags":["technology","terminal","cli","theming","rice"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1607877361964-bf792b65e593?fit=crop&w=1400&h=700&q=75"}}]